import streamlit as st
import os
from dotenv import load_dotenv
import json
import re
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def extract_json_from_response(content):
    """å¾å›æ‡‰ä¸­æ“·å– JSON å…§å®¹"""
    # å˜—è©¦æ‰¾å‡º JSON å…§å®¹çš„é–‹å§‹å’ŒçµæŸ
    try:
        # æ‰¾å‡ºç¬¬ä¸€å€‹ { å’Œæœ€å¾Œä¸€å€‹ } çš„ä½ç½®
        start = content.find('{')
        end = content.rfind('}') + 1
        if start != -1 and end != -1:
            json_str = content[start:end]
            return json.loads(json_str)
    except:
        pass
    return None

def analyze_research_purpose(research_purpose):
    """åˆ†æç ”ç©¶ç›®çš„ä¸¦ç”¢ç”Ÿæ–‡ç»æ¢è¨æ¶æ§‹"""
    system_prompt = """You are a professional research methodology expert specializing in literature review structure planning.
Please respond in Traditional Chinese for all content except search queries.
For search queries, provide complete English sentences that are effective for academic database searches.

The response must strictly follow this JSON format with no additional text:
{
    "sections": [
        {
            "title_zh": "ä¸­æ–‡ç« ç¯€æ¨™é¡Œ",
            "title_en": "English Section Title",
            "description": "æœ¬ç« ç¯€æ‡‰è©²æ¢è¨çš„é‡é»",
            "search_queries": [
                {
                    "focus": "æœå°‹é‡é»æè¿°",
                    "query": "A complete English sentence for academic database search that focuses on specific aspects of the research"
                }
            ]
        }
    ]
}"""

    user_prompt = f"""Based on the following research purpose, please provide:
1. 3-5 appropriate literature review section titles (in both Chinese and English)
2. Description of key points for each section
3. 2-3 search queries for each section that:
   - Can be directly used in academic databases
   - Use complete, natural English sentences
   - Cover the most important search aspects
   - Consider research trends in the past five years

Research Purpose:
{research_purpose}

Please strictly follow the JSON format specified in the system message, with no additional explanation."""

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        content = response.choices[0].message.content.strip()
        
        # å˜—è©¦ç›´æ¥è§£æ
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±æ•—ï¼Œå˜—è©¦æ“·å– JSON éƒ¨åˆ†
            result = extract_json_from_response(content)
            if result:
                return result
            else:
                st.error("ç„¡æ³•è§£æå›æ‡‰ç‚º JSON æ ¼å¼")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def analyze_multiple_literature(section_title, literature_texts):
    """åˆ†æå¤šç¯‡æ–‡ç»å…§å®¹ä¸¦ç”¢ç”Ÿæ‘˜è¦åˆ†æ"""
    system_prompt = """æ‚¨æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡ç»åˆ†æå°ˆå®¶ï¼Œè«‹å”åŠ©åˆ†æè¼¸å…¥çš„å¤šç¯‡æ–‡ç»å…§å®¹ã€‚
è«‹ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡çš„ç”¨å­—ç¿’æ…£æ’°å¯«åˆ†æå…§å®¹ï¼Œæ³¨æ„ï¼š
- ä½¿ç”¨å°ç£çš„å­¸è¡“ç”¨èªå’Œå°ˆæ¥­è¡“èª
- ä½¿ç”¨å°ç£çš„æ¨™é»ç¬¦è™Ÿç¿’æ…£ï¼ˆå¦‚ï¼šä½¿ç”¨ã€Œã€å¼•è™Ÿï¼‰
- ä½¿ç”¨å°ç£çš„èªæ°£è©å’Œè¡¨é”æ–¹å¼
- é¿å…ä½¿ç”¨ä¸­åœ‹å¤§é™¸çš„ç”¨èªç¿’æ…£
å¾è¼¸å…¥çš„æ–‡å­—ä¸­è­˜åˆ¥å‡ºæ¯ç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦å…§å®¹ï¼Œä¸¦é€²è¡Œåˆ†ææ•´ç†ã€‚
æ¯ç¯‡æ–‡ç»ä¹‹é–“æ‡‰è©²æ˜¯ç”¨é€£çºŒå…©å€‹æ›è¡Œç¬¦è™Ÿåˆ†éš”ã€‚"""

    user_prompt = f"""è«‹åˆ†æä»¥ä¸‹å¤šç¯‡æ–‡ç»å…§å®¹ï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ•´ç†æ¯ä¸€ç¯‡ï¼š
1. è­˜åˆ¥ä¸¦æ“·å–æ¯ç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼
2. æ“·å–æ¯ç¯‡æ–‡ç»çš„æ‘˜è¦å…§å®¹
3. åˆ†ææ¯ç¯‡æ–‡ç»èˆ‡ã€Œ{section_title}ã€ç« ç¯€çš„ç›¸é—œæ€§
4. æä¾›æ¯ç¯‡æ–‡ç»å°è©²ç« ç¯€çš„ä¸»è¦è²¢ç»
5. å»ºè­°åœ¨æ–‡ç»å›é¡§ä¸­å¦‚ä½•å¼•ç”¨æ¯ç¯‡æ–‡ç»

è¼¸å…¥å…§å®¹ï¼š
{literature_texts}

è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼ŒåŒ…å«æ‰€æœ‰æ–‡ç»çš„åˆ†æçµæœï¼š
{{
    "literature": [
        {{
            "citation": "APAå¼•ç”¨æ ¼å¼",
            "abstract": "æ‘˜è¦å…§å®¹",
            "relevance": "èˆ‡ç« ç¯€çš„ç›¸é—œæ€§åˆ†æ",
            "contribution": "å°ç« ç¯€çš„ä¸»è¦è²¢ç»",
            "usage_suggestion": "åœ¨æ–‡ç»å›é¡§ä¸­çš„å¼•ç”¨å»ºè­°"
        }}
    ]
}}"""

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        content = response.choices[0].message.content.strip()
        
        try:
            result = json.loads(content)
            if 'literature' in result:
                return result['literature']
            return None
        except json.JSONDecodeError:
            result = extract_json_from_response(content)
            if result and 'literature' in result:
                return result['literature']
            else:
                st.error("ç„¡æ³•è§£ææ–‡ç»åˆ†æçµæœ")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"åˆ†ææ–‡ç»æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def generate_literature_review(section_title, literature_list):
    """ç”¢ç”Ÿæ–‡ç»æ¢è¨å…§å®¹"""
    system_prompt = """æ‚¨æ˜¯ä¸€ä½æ·±è€•æ–¼ç ”ç©¶é ˜åŸŸçš„å°ˆæ¥­å­¸è¡“ç ”ç©¶è€…ï¼Œæ“…é•·æ•´åˆæ–‡ç»ä¸¦æ’°å¯«å…·æœ‰æ·±åº¦çš„æ–‡ç»æ¢è¨ã€‚

ã€ç”¨å­—è¦ç¯„ã€‘
1. ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡çš„å­¸è¡“ç”¨èªï¼š
   - ã€Œç ”ç©¶ã€è€Œéã€Œç ”è®¨ã€
   - ã€Œæ­·ç¨‹ã€è€Œéã€Œè¿‡ç¨‹ã€
   - ã€Œæ–¹æ³•ã€è€Œéã€Œæ–¹å¼ã€
   - ã€Œæ¢è¨ã€è€Œéã€Œæ¢è®¨ã€
   - ã€Œå¯¦æ–½ã€è€Œéã€Œå®è¡Œã€
   - ã€Œæˆæ•ˆã€è€Œéã€Œæˆæœã€
   - ã€Œè­°é¡Œã€è€Œéã€Œè¯¾é¢˜ã€
   - ã€Œå»ºè­°ã€è€Œéã€Œå»ºè®®ã€

2. ä½¿ç”¨å°ç£çš„æ¨™é»ç¬¦è™Ÿï¼š
   - ä½¿ç”¨ã€Œã€ä½œç‚ºä¸­æ–‡å¼•è™Ÿ
   - ä½¿ç”¨ã€ã€ä½œç‚ºå¼•è™Ÿä¸­çš„å¼•è™Ÿ
   - ç ´æŠ˜è™Ÿä½¿ç”¨ã€Œâ”€â”€ã€
   - æ›¸åè™Ÿä½¿ç”¨ã€Šã€‹
   - ç¯‡åè™Ÿä½¿ç”¨ã€ˆã€‰

3. ä½¿ç”¨å°ç£çš„è¡¨é”æ–¹å¼ï¼š
   - ã€Œç›®å‰ã€è€Œéã€Œå½“å‰ã€
   - ã€Œä¹‹å¾Œã€è€Œéã€Œä¹‹åã€
   - ã€Œå› æ­¤ã€è€Œéã€Œæ‰€ä»¥ã€
   - ã€Œç„¶è€Œã€è€Œéã€Œä½†æ˜¯ã€
   - ã€Œè—‰ç”±ã€è€Œéã€Œé€šè¿‡ã€
   - ã€Œæ ¹æ“šã€è€Œéã€ŒæŒ‰ç…§ã€
   - ã€Œé¡¯ç¤ºã€è€Œéã€Œè¡¨æ˜ã€

4. ä½¿ç”¨å°ç£çš„å°ˆæ¥­è¡“èªï¼š
   - ã€Œè³‡è¨Šç§‘æŠ€ã€è€Œéã€Œä¿¡æ¯æŠ€æœ¯ã€
   - ã€Œé›»è…¦ã€è€Œéã€Œè®¡ç®—æœºã€
   - ã€Œæ¼”ç®—æ³•ã€è€Œéã€Œç®—æ³•ã€
   - ã€Œäººå·¥æ™ºæ…§ã€è€Œéã€Œäººå·¥æ™ºèƒ½ã€
   - ã€Œè³‡æ–™åº«ã€è€Œéã€Œæ•°æ®åº“ã€
   - ã€Œç¶²éš›ç¶²è·¯ã€è€Œéã€Œäº’è”ç½‘ã€

åœ¨æ’°å¯«æ™‚ï¼š
1. æ ¹æ“šç ”ç©¶ä¸»é¡Œèª¿æ•´å°ˆæ¥­è¡“èªå’Œè«–è¿°æ–¹å¼
2. è‡ªç„¶åœ°èå…¥ç ”ç©¶è€…çš„è§€å¯Ÿèˆ‡ç¶“é©—
3. å±•ç¾æ·±å…¥çš„æ€è€ƒéç¨‹å’Œé‚è¼¯æ¨æ¼”
4. ç¶­æŒå­¸è¡“åš´è¬¹æ€§å’Œå‰µæ–°æ€ç¶­
5. ç¢ºä¿æ–‡ç« çµæ§‹å®Œæ•´ä¸”è«–è¿°æµæš¢"""

    user_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹æ–‡ç»è³‡æ–™ï¼Œç‚ºã€Œ{section_title}ã€ç« ç¯€æ’°å¯«æ–‡ç»æ¢è¨å…§å®¹ã€‚

æ–‡ç»è³‡æ–™ï¼š
{json.dumps(literature_list, ensure_ascii=False, indent=2)}

ã€æ’°å¯«è¦æ±‚ã€‘
1. æ–‡ç« é¢¨æ ¼ï¼š
   - é‹ç”¨ç¬¬ä¸€äººç¨±æ•˜è¿°ï¼Œå±•ç¾ç ”ç©¶è€…çš„å°ˆæ¥­æ´å¯Ÿ
   - ä¿æŒå­¸è¡“åš´è¬¹æ€§çš„åŒæ™‚ï¼Œèå…¥å€‹äººè§€é»å’Œç¶“é©—
   - æ®µè½ä¹‹é–“è¦æœ‰è‡ªç„¶çš„é‚è¼¯æ¨å±•
   - é¿å…éæ–¼åˆ¶å¼åŒ–çš„è¡¨é”æ–¹å¼

2. è«–è¿°æ–¹å¼ï¼š
   - å¾æ–‡ç»å›é¡§ä¸­æ‰¾å‡ºç ”ç©¶è¶¨å‹¢å’Œç¼ºå£
   - çµåˆä¸åŒæ–‡ç»çš„è§€é»é€²è¡Œæ¯”è¼ƒå’Œæ•´åˆ
   - å±•ç¾æ€è€ƒçš„æ·±åº¦èˆ‡å»£åº¦
   - é©åº¦èå…¥é ˜åŸŸå°ˆæ¥­è¡“èª

3. èªè¨€è¡¨é”ï¼š
   - ä½¿ç”¨æµæš¢ä¸”å°ˆæ¥­çš„å­¸è¡“ç”¨èª
   - é¿å…éåº¦å †ç Œæ–‡ç»
   - ä¿æŒè«–è¿°çš„é€£è²«æ€§å’Œé‚è¼¯æ€§
   - é©æ™‚ä½¿ç”¨è½‰æŠ˜èªå¥å¢åŠ æ–‡ç« æµæš¢åº¦

ã€å…§å®¹æ¶æ§‹ã€‘ï¼ˆè‡³å°‘ 800 å­—ï¼‰ï¼š

1. ç ”ç©¶è„ˆçµ¡èˆ‡è¶¨å‹¢åˆ†æï¼ˆç´„ 300 å­—ï¼‰ï¼š
   - åˆ†æè©²é ˜åŸŸçš„ç ”ç©¶ç™¼å±•è„ˆçµ¡
   - æŒ‡å‡ºä¸»è¦ç ”ç©¶æ–¹å‘å’Œè¶¨å‹¢
   - æ•´åˆä¸åŒå­¸è€…çš„è§€é»
   - çªé¡¯é‡è¦çš„ç ”ç©¶ç™¼ç¾

2. ç†è«–èˆ‡å¯¦å‹™çš„æ•´åˆï¼ˆç´„ 300 å­—ï¼‰ï¼š
   - åˆ†æç†è«–åŸºç¤å’Œå¯¦å‹™æ‡‰ç”¨
   - æ¯”è¼ƒä¸åŒç ”ç©¶çš„æ–¹æ³•å’Œç™¼ç¾
   - è¨è«–ç ”ç©¶çµæœçš„å¯¦å‹™æ„æ¶µ
   - æŒ‡å‡ºç†è«–èˆ‡å¯¦å‹™çš„é€£çµ

3. ç ”ç©¶ç¼ºå£èˆ‡æœªä¾†æ–¹å‘ï¼ˆç´„ 200 å­—ï¼‰ï¼š
   - æ­¸ç´ç›®å‰ç ”ç©¶çš„é™åˆ¶
   - æŒ‡å‡ºå€¼å¾—æ·±å…¥æ¢è¨çš„è­°é¡Œ
   - æå‡ºå¯èƒ½çš„ç ”ç©¶æ–¹å‘
   - èªªæ˜ç ”ç©¶åƒ¹å€¼å’Œé‡è¦æ€§

è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼š
{{
    "literature_review": "å®Œæ•´çš„æ–‡ç»æ¢è¨å…§å®¹",
    "references": [
        "APAæ ¼å¼çš„åƒè€ƒæ–‡ç»åˆ—è¡¨"
    ],
    "key_findings": [
        "é‡è¦ç™¼ç¾1",
        "é‡è¦ç™¼ç¾2"
    ],
    "research_gaps": [
        "ç ”ç©¶ç¼ºå£1",
        "ç ”ç©¶ç¼ºå£2"
    ]
}}

æ³¨æ„äº‹é …ï¼š
1. æ–‡ç»å¼•ç”¨è¦è‡ªç„¶åœ°èå…¥è«–è¿°ä¸­ï¼ˆä½¿ç”¨ APA æ ¼å¼ï¼‰
2. ç¢ºä¿ä¸åŒæ®µè½ä¹‹é–“çš„é‚è¼¯é€£è²«æ€§
3. é©ç•¶ä½¿ç”¨è½‰æŠ˜èªå¥å¢åŠ æ–‡ç« æµæš¢åº¦
4. åœ¨ä¿æŒå®¢è§€æ€§çš„åŒæ™‚ï¼Œä¹Ÿè¦å±•ç¾å€‹äººçš„å°ˆæ¥­åˆ¤æ–·"""

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        content = response.choices[0].message.content.strip()
        
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            result = extract_json_from_response(content)
            if result:
                return result
            else:
                st.error("ç„¡æ³•è§£ææ–‡ç»æ¢è¨ç”¢ç”Ÿçµæœ")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"ç”¢ç”Ÿæ–‡ç»æ¢è¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def load_research_purpose():
    """è®€å–å„²å­˜çš„ç ”ç©¶ç›®çš„å…§å®¹"""
    try:
        with open('.research_purpose.tmp', 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('research_purpose', '')
    except (FileNotFoundError, json.JSONDecodeError):
        return ''

def main():
    st.title("ğŸ“š ç ”ç©¶æ–‡ç»æ¶æ§‹åˆ†æå·¥å…·")
    st.write("æœ¬å·¥å…·å¯ä»¥å”åŠ©æ‚¨æ ¹æ“šç ”ç©¶ç›®çš„è¦åŠƒæ–‡ç»æ¢è¨æ¶æ§‹ï¼Œä¸¦æä¾›é©åˆçš„æœå°‹é—œéµå­—ã€‚")
    
    # åˆå§‹åŒ– session state
    if 'sections' not in st.session_state:
        st.session_state.sections = None
    if 'literature_data' not in st.session_state:
        st.session_state.literature_data = {}
    if 'literature_reviews' not in st.session_state:
        st.session_state.literature_reviews = {}
    
    # è®€å–å…ˆå‰ç”¢ç”Ÿçš„ç ”ç©¶ç›®çš„
    saved_purpose = load_research_purpose()
    
    # è¼¸å…¥å€åŸŸ
    research_purpose = st.text_area(
        "è«‹è²¼å…¥æ‚¨çš„ç ”ç©¶ç›®çš„å…§å®¹",
        value=saved_purpose,  # ä½¿ç”¨å„²å­˜çš„å…§å®¹ä½œç‚ºé è¨­å€¼
        height=200,
        help="å°‡æ‚¨æ’°å¯«çš„ç ”ç©¶ç›®çš„å…§å®¹è²¼åœ¨é€™è£¡"
    )
    
    if st.button("ç”¢ç”Ÿæ–‡ç»æ¢è¨æ¶æ§‹"):
        if not research_purpose:
            st.error("è«‹å…ˆè¼¸å…¥ç ”ç©¶ç›®çš„å…§å®¹")
            return
            
        with st.spinner("æ­£åœ¨åˆ†æç ”ç©¶ç›®çš„ä¸¦ç”¢ç”Ÿæ¶æ§‹..."):
            result = analyze_research_purpose(research_purpose)
            if result and 'sections' in result:
                st.session_state.sections = result['sections']
                st.session_state.literature_data = {
                    section['title_zh']: {'literature': []}
                    for section in result['sections']
                }
    
    # é¡¯ç¤ºçµæœå’Œæ”¶é›†æ–‡ç»
    if st.session_state.sections:
        for section in st.session_state.sections:
            st.markdown("---")
            st.markdown(f"## {section['title_zh']}")
            st.markdown(f"**é‡é»èªªæ˜ï¼š**\n{section['description']}")
            
            st.markdown("**å»ºè­°æœå°‹å­—ä¸²ï¼š**")
            for search in section['search_queries']:
                st.markdown(f"- {search['focus']}:")
                st.code(search['query'], language="text")
            
            # æ–‡ç»æ”¶é›†å€åŸŸ
            st.markdown("### ğŸ“‘ æ–‡ç»æ”¶é›†")
            
            # æ–‡ç»è¼¸å…¥
            new_literature = st.text_area(
                "è«‹è²¼å…¥å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼èˆ‡æ‘˜è¦ï¼ˆæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œï¼‰",
                key=f"literature_{section['title_zh']}",
                height=400,
                help="å¾ SciSpace è¤‡è£½å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦ï¼Œæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œ"
            )
            
            col1, col2 = st.columns(2)
            
            # æ–°å¢æ–‡ç»æŒ‰éˆ•
            with col1:
                if st.button(f"åˆ†æä¸¦æ–°å¢æ–‡ç»åˆ°ã€Œ{section['title_zh']}ã€", key=f"add_{section['title_zh']}"):
                    if new_literature.strip():
                        with st.spinner("æ­£åœ¨åˆ†ææ–‡ç»å…§å®¹..."):
                            analysis_results = analyze_multiple_literature(section['title_zh'], new_literature)
                            if analysis_results:
                                st.session_state.literature_data[section['title_zh']]['literature'].extend(analysis_results)
                                st.success(f"å·²æˆåŠŸåˆ†æä¸¦æ–°å¢ {len(analysis_results)} ç¯‡æ–‡ç»")
            
            # ç”¢ç”Ÿæ–‡ç»æ¢è¨æŒ‰éˆ•
            with col2:
                if st.button(f"ç”¢ç”Ÿã€Œ{section['title_zh']}ã€çš„æ–‡ç»æ¢è¨", key=f"review_{section['title_zh']}"):
                    if st.session_state.literature_data[section['title_zh']]['literature']:
                        with st.spinner("æ­£åœ¨ç”¢ç”Ÿæ–‡ç»æ¢è¨å…§å®¹..."):
                            review_result = generate_literature_review(
                                section['title_zh'],
                                st.session_state.literature_data[section['title_zh']]['literature']
                            )
                            if review_result:
                                st.session_state.literature_reviews[section['title_zh']] = review_result
                                st.success("å·²æˆåŠŸç”¢ç”Ÿæ–‡ç»æ¢è¨å…§å®¹")
                    else:
                        st.warning("è«‹å…ˆæ–°å¢æ–‡ç»å†ç”¢ç”Ÿæ–‡ç»æ¢è¨")
            
            # é¡¯ç¤ºå·²æ”¶é›†çš„æ–‡ç»
            if st.session_state.literature_data[section['title_zh']]['literature']:
                st.markdown("#### å·²æ”¶é›†çš„æ–‡ç»")
                for i, lit in enumerate(st.session_state.literature_data[section['title_zh']]['literature']):
                    with st.expander(f"æ–‡ç» {i+1}"):
                        st.markdown("**å¼•ç”¨æ ¼å¼ï¼š**")
                        st.markdown(lit['citation'])
                        st.markdown("**æ‘˜è¦ï¼š**")
                        st.markdown(lit['abstract'])
                        st.markdown("**èˆ‡æœ¬ç« ç¯€çš„ç›¸é—œæ€§ï¼š**")
                        st.markdown(lit['relevance'])
                        st.markdown("**ä¸»è¦è²¢ç»ï¼š**")
                        st.markdown(lit['contribution'])
                        st.markdown("**å»ºè­°å¼•ç”¨æ–¹å¼ï¼š**")
                        st.markdown(lit['usage_suggestion'])
            
            # é¡¯ç¤ºæ–‡ç»æ¢è¨å…§å®¹
            if section['title_zh'] in st.session_state.literature_reviews:
                review = st.session_state.literature_reviews[section['title_zh']]
                with st.expander("ğŸ“ æ–‡ç»æ¢è¨å…§å®¹", expanded=True):
                    st.markdown("### æ–‡ç»æ¢è¨")
                    st.markdown(review['literature_review'])
                    
                    st.markdown("### é‡è¦ç™¼ç¾")
                    for finding in review['key_findings']:
                        st.markdown(f"- {finding}")
                    
                    st.markdown("### ç ”ç©¶ç¼ºå£")
                    for gap in review['research_gaps']:
                        st.markdown(f"- {gap}")
                    
                    st.markdown("### åƒè€ƒæ–‡ç»")
                    for ref in review['references']:
                        st.markdown(f"- {ref}")
        
        # æä¾›å¯¦ç”¨é€£çµ
        st.markdown("---")
        st.markdown("""
        ### ğŸ“– æ“ä½œæç¤º
        1. ä½¿ç”¨ä¸Šæ–¹çš„æœå°‹å­—ä¸²åœ¨ [SciSpace](https://typeset.io/) æœå°‹ç›¸é—œæ–‡ç»
        2. å¾æœå°‹çµæœä¸­è¤‡è£½å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦
        3. å°‡è¤‡è£½çš„å…§å®¹ç›´æ¥è²¼åˆ°å°æ‡‰ç« ç¯€çš„è¼¸å…¥æ¡†ä¸­ï¼ˆæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œï¼‰
        4. é»é¸ã€Œåˆ†æä¸¦æ–°å¢æ–‡ç»ã€æŒ‰éˆ•ï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†æä¸¦æ•´ç†æ‰€æœ‰æ–‡ç»å…§å®¹
        5. æ”¶é›†è¶³å¤ æ–‡ç»å¾Œï¼Œé»é¸ã€Œç”¢ç”Ÿæ–‡ç»æ¢è¨ã€æŒ‰éˆ•ç”¢ç”Ÿè©²ç« ç¯€çš„æ–‡ç»æ¢è¨å…§å®¹
        6. å»ºè­°æ¯å€‹ç« ç¯€è‡³å°‘æ”¶é›† 3-5 ç¯‡ç›¸é—œæ–‡ç»
        """)

if __name__ == "__main__":
    main() 