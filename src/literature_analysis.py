import streamlit as st
import os
from dotenv import load_dotenv
import json
import re
from openai import OpenAI

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def extract_json_from_response(content):
    """å¾å›æ‡‰ä¸­æ“·å– JSON å…§å®¹"""
    # å˜—è©¦æ‰¾å‡º JSON å…§å®¹çš„é–‹å§‹å’ŒçµæŸ
    try:
        # æ‰¾å‡ºç¬¬ä¸€å€‹ { å’Œæœ€å¾Œä¸€å€‹ } çš„ä½ç½®
        start = content.find('{')
        end = content.rfind('}') + 1
        if start != -1 and end != -1:
            json_str = content[start:end]
            return json.loads(json_str)
    except:
        pass
    return None

def analyze_research_purpose(research_purpose):
    """åˆ†æç ”ç©¶ç›®çš„ä¸¦ç”¢ç”Ÿæ–‡ç»æ¢è¨æ¶æ§‹"""
    system_prompt = """You are a professional design research methodology expert specializing in literature review structure planning.
Please respond in Traditional Chinese (Taiwan) and follow these language guidelines:

1. ä½¿ç”¨å°ç£çš„è¨­è¨ˆç ”ç©¶ç”¨èªï¼š
   - ã€Œè¨­è¨ˆæ€è€ƒã€è€Œéã€Œè®¾è®¡æ€ç»´ã€
   - ã€Œä½¿ç”¨è€…ç¶“é©—ã€è€Œéã€Œç”¨æˆ·ä½“éªŒã€
   - ã€Œä»‹é¢è¨­è¨ˆã€è€Œéã€Œç•Œé¢è®¾è®¡ã€
   - ã€Œäº’å‹•è¨­è¨ˆã€è€Œéã€Œäº¤äº’è®¾è®¡ã€
   - ã€Œè¨­è¨ˆæ–¹æ³•ã€è€Œéã€Œè®¾è®¡æ–¹æ³•è®ºã€
   - ã€Œè¨­è¨ˆå¯¦å‹™ã€è€Œéã€Œè®¾è®¡å®è·µã€

2. ä½¿ç”¨å°ç£çš„å°ˆæ¥­è¡“èªï¼š
   - ã€Œä½¿ç”¨è€…ã€è€Œéã€Œç”¨æˆ·ã€
   - ã€Œä»‹é¢ã€è€Œéã€Œç•Œé¢ã€
   - ã€Œäº’å‹•ã€è€Œéã€Œäº¤äº’ã€
   - ã€Œè¨­è¨ˆæµç¨‹ã€è€Œéã€Œè®¾è®¡æµç¨‹ã€
   - ã€Œè¨­è¨ˆç­–ç•¥ã€è€Œéã€Œè®¾è®¡ç­–ç•¥ã€

3. ä½¿ç”¨å°ç£çš„è¡¨é”æ–¹å¼ï¼š
   - ã€Œç›®å‰ã€è€Œéã€Œå½“å‰ã€
   - ã€Œä¹‹å¾Œã€è€Œéã€Œä¹‹åã€
   - ã€Œå› æ­¤ã€è€Œéã€Œæ‰€ä»¥ã€
   - ã€Œç„¶è€Œã€è€Œéã€Œä½†æ˜¯ã€
   - ã€Œè—‰ç”±ã€è€Œéã€Œé€šè¿‡ã€
   - ã€Œæ ¹æ“šã€è€Œéã€ŒæŒ‰ç…§ã€

4. æ–‡ç»æ¢è¨æ¶æ§‹åˆ†æé‡é»ï¼š
   - ç ”ç©¶ç›®çš„ä¸­çš„æ ¸å¿ƒå•é¡Œ
   - ç ”ç©¶æ–¹æ³•èˆ‡é€”å¾‘
   - ç†è«–åŸºç¤éœ€æ±‚
   - å¯¦å‹™æ‡‰ç”¨é¢å‘
   - é æœŸç ”ç©¶è²¢ç»
   - ç ”ç©¶ç¯„åœç•Œå®š
   - é‡è¦ç ”ç©¶è®Šé …
   - ç ”ç©¶å‰µæ–°è§€é»

5. ç« ç¯€è¦åŠƒåŸå‰‡ï¼š
   - ç¢ºä¿ç« ç¯€æ¶µè“‹ç ”ç©¶ç›®çš„çš„æ‰€æœ‰é‡è¦é¢å‘
   - ç”±åŸºç¤ç†è«–åˆ°æ‡‰ç”¨å¯¦å‹™å¾ªåºæ¼¸é€²
   - å„ç« ç¯€ä¹‹é–“è¦æœ‰é‚è¼¯é€£è²«æ€§
   - é…åˆç ”ç©¶æ–¹æ³•è¦åŠƒå°æ‡‰çš„ç†è«–åŸºç¤
   - é‡å°å‰µæ–°è§€é»æä¾›å……åˆ†çš„ç†è«–æ”¯æŒ

6. å°æ¨™é¡Œè¨­è¨ˆåŸå‰‡ï¼š
   - ç·Šæ‰£ç ”ç©¶æ ¸å¿ƒç›®æ¨™
   - åæ˜ è©²æ®µè½çš„ä¸»è¦è«–è¿°é‡é»
   - ç¬¦åˆå­¸è¡“å¯«ä½œè¦ç¯„
   - å…·æœ‰é‚è¼¯å±¤æ¬¡æ€§
   - èƒ½æ¸…æ¥šæŒ‡å¼•è®€è€…ç†è§£æ–‡ç« çµæ§‹
   - æ¯å€‹ç« ç¯€ 3-4 å€‹å°æ¨™é¡Œ
   - ç¢ºä¿å°æ¨™é¡Œä¹‹é–“çš„é€£è²«æ€§
   - ç”±æ·ºå…¥æ·±çš„æ¼¸é€²å¼å®‰æ’

7. æœå°‹ç­–ç•¥è¦åŠƒï¼š
   - é…åˆå„ç« ç¯€ä¸»é¡Œè¨­è¨ˆç²¾ç¢ºçš„æœå°‹ç­–ç•¥
   - è€ƒæ…®è¿‘äº”å¹´çš„ç ”ç©¶è¶¨å‹¢
   - æ¶µè“‹ç†è«–èˆ‡å¯¦å‹™çš„ç›¸é—œæ–‡ç»
   - ç‰¹åˆ¥é—œæ³¨èˆ‡ç ”ç©¶å‰µæ–°é»ç›¸é—œçš„æ–‡ç»
   - ç´å…¥è·¨é ˜åŸŸçš„ç›¸é—œç ”ç©¶

The response must strictly follow this JSON format with no additional text:
{
    "sections": [
        {
            "title_zh": "ä¸­æ–‡ç« ç¯€æ¨™é¡Œ",
            "title_en": "English Section Title",
            "description": "æœ¬ç« ç¯€æ‡‰è©²æ¢è¨çš„é‡é»",
            "subtitles": [
                {
                    "subtitle_zh": "ä¸­æ–‡å°æ¨™é¡Œ",
                    "subtitle_en": "English Subtitle",
                    "content_focus": "æ­¤å°ç¯€æ‡‰è©²æ¢è¨çš„å…·é«”å…§å®¹é‡é»"
                }
            ],
            "search_queries": [
                {
                    "focus": "æœå°‹é‡é»æè¿°",
                    "query": "A complete English sentence for academic database search that focuses on specific aspects of the research"
                }
            ]
        }
    ]
}"""

    user_prompt = f"""Based on the following research purpose, please analyze it thoroughly and provide:

1. Research Purpose Analysis:
   - Core research questions and objectives
   - Research methodology and approaches
   - Theoretical foundation requirements
   - Practical application aspects
   - Expected research contributions
   - Research scope and limitations
   - Key research variables
   - Innovative perspectives

2. Literature Review Structure (3-5 sections):
   - Each section must directly support aspects of the research purpose
   - Sections should progress logically from theoretical to practical
   - Include both theoretical foundations and practical applications
   - Address innovative aspects of the research
   - Consider interdisciplinary perspectives if relevant

3. For each section, provide:
   - Clear and specific section titles (both Chinese and English)
   - 3-4 subtitles that:
     * Reflect the core research objectives
     * Show logical progression of ideas
     * Cover key aspects of the section
     * Guide readers through the content structure
   - Detailed description of key points to be discussed
   - 2-3 targeted search queries that:
     * Can be directly used in academic databases
     * Use complete, natural English sentences
     * Cover the most important search aspects
     * Consider research trends in the past five years
     * Focus on specific aspects of the research purpose

Research Purpose:
{research_purpose}

Please strictly follow the JSON format specified in the system message, with no additional explanation."""

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        content = response.choices[0].message.content.strip()
        
        # å˜—è©¦ç›´æ¥è§£æ
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±æ•—ï¼Œå˜—è©¦æ“·å– JSON éƒ¨åˆ†
            result = extract_json_from_response(content)
            if result:
                return result
            else:
                st.error("ç„¡æ³•è§£æå›æ‡‰ç‚º JSON æ ¼å¼")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def analyze_multiple_literature(section_title, literature_texts):
    """åˆ†æå¤šç¯‡æ–‡ç»å…§å®¹ä¸¦ç”¢ç”Ÿæ‘˜è¦åˆ†æ"""
    system_prompt = """æ‚¨æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡ç»åˆ†æå°ˆå®¶ï¼Œè«‹å”åŠ©åˆ†æè¼¸å…¥çš„å¤šç¯‡æ–‡ç»å…§å®¹ã€‚
è«‹ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡çš„ç”¨å­—ç¿’æ…£æ’°å¯«åˆ†æå…§å®¹ï¼Œæ³¨æ„ï¼š
- ä½¿ç”¨å°ç£çš„å­¸è¡“ç”¨èªå’Œå°ˆæ¥­è¡“èª
- ä½¿ç”¨å°ç£çš„æ¨™é»ç¬¦è™Ÿç¿’æ…£ï¼ˆå¦‚ï¼šä½¿ç”¨ã€Œã€å¼•è™Ÿï¼‰
- ä½¿ç”¨å°ç£çš„èªæ°£è©å’Œè¡¨é”æ–¹å¼
- é¿å…ä½¿ç”¨ä¸­åœ‹å¤§é™¸çš„ç”¨èªç¿’æ…£
å¾è¼¸å…¥çš„æ–‡å­—ä¸­è­˜åˆ¥å‡ºæ¯ç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦å…§å®¹ï¼Œä¸¦é€²è¡Œåˆ†ææ•´ç†ã€‚
æ¯ç¯‡æ–‡ç»ä¹‹é–“æ‡‰è©²æ˜¯ç”¨é€£çºŒå…©å€‹æ›è¡Œç¬¦è™Ÿåˆ†éš”ã€‚"""

    user_prompt = f"""è«‹åˆ†æä»¥ä¸‹å¤šç¯‡æ–‡ç»å…§å®¹ï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ•´ç†æ¯ä¸€ç¯‡ï¼š
1. è­˜åˆ¥ä¸¦æ“·å–æ¯ç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼
2. æ“·å–æ¯ç¯‡æ–‡ç»çš„æ‘˜è¦å…§å®¹
3. åˆ†ææ¯ç¯‡æ–‡ç»èˆ‡ã€Œ{section_title}ã€ç« ç¯€çš„ç›¸é—œæ€§
4. æä¾›æ¯ç¯‡æ–‡ç»å°è©²ç« ç¯€çš„ä¸»è¦è²¢ç»
5. å»ºè­°åœ¨æ–‡ç»å›é¡§ä¸­å¦‚ä½•å¼•ç”¨æ¯ç¯‡æ–‡ç»

è¼¸å…¥å…§å®¹ï¼š
{literature_texts}

è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼ŒåŒ…å«æ‰€æœ‰æ–‡ç»çš„åˆ†æçµæœï¼š
{{
    "literature": [
        {{
            "citation": "APAå¼•ç”¨æ ¼å¼",
            "abstract": "æ‘˜è¦å…§å®¹",
            "relevance": "èˆ‡ç« ç¯€çš„ç›¸é—œæ€§åˆ†æ",
            "contribution": "å°ç« ç¯€çš„ä¸»è¦è²¢ç»",
            "usage_suggestion": "åœ¨æ–‡ç»å›é¡§ä¸­çš„å¼•ç”¨å»ºè­°"
        }}
    ]
}}"""

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3
        )
        content = response.choices[0].message.content.strip()
        
        try:
            result = json.loads(content)
            if 'literature' in result:
                return result['literature']
            return None
        except json.JSONDecodeError:
            result = extract_json_from_response(content)
            if result and 'literature' in result:
                return result['literature']
            else:
                st.error("ç„¡æ³•è§£ææ–‡ç»åˆ†æçµæœ")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"åˆ†ææ–‡ç»æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def generate_literature_review(section_title, literature_list):
    """ç”¢ç”Ÿæ–‡ç»æ¢è¨å…§å®¹"""
    system_prompt = """ä½ æ˜¯ä¸€ä½æ·±è€•æ–¼è¨­è¨ˆç ”ç©¶é ˜åŸŸçš„å°ˆæ¥­å­¸è¡“ç ”ç©¶è€…ï¼Œæ“…é•·æ•´åˆè¨­è¨ˆç†è«–èˆ‡å¯¦å‹™ã€‚è«‹ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡æ’°å¯«ï¼Œä¸¦éµå¾ªä»¥ä¸‹è¦ç¯„ï¼š

1. ä½¿ç”¨å°ç£çš„è¨­è¨ˆç ”ç©¶ç”¨èªï¼š
   - ã€Œè¨­è¨ˆæ€è€ƒã€è€Œéã€Œè®¾è®¡æ€ç»´ã€
   - ã€Œä½¿ç”¨è€…ç¶“é©—ã€è€Œéã€Œç”¨æˆ·ä½“éªŒã€
   - ã€Œä»‹é¢è¨­è¨ˆã€è€Œéã€Œç•Œé¢è®¾è®¡ã€
   - ã€Œäº’å‹•è¨­è¨ˆã€è€Œéã€Œäº¤äº’è®¾è®¡ã€
   - ã€Œè¨­è¨ˆæ–¹æ³•ã€è€Œéã€Œè®¾è®¡æ–¹æ³•è®ºã€
   - ã€Œè¨­è¨ˆå¯¦å‹™ã€è€Œéã€Œè®¾è®¡å®è·µã€

2. ä½¿ç”¨å°ç£çš„å°ˆæ¥­è¡“èªï¼š
   - ã€Œä½¿ç”¨è€…ã€è€Œéã€Œç”¨æˆ·ã€
   - ã€Œä»‹é¢ã€è€Œéã€Œç•Œé¢ã€
   - ã€Œäº’å‹•ã€è€Œéã€Œäº¤äº’ã€
   - ã€Œè¨­è¨ˆæµç¨‹ã€è€Œéã€Œè®¾è®¡æµç¨‹ã€
   - ã€Œè¨­è¨ˆç­–ç•¥ã€è€Œéã€Œè®¾è®¡ç­–ç•¥ã€

3. ä½¿ç”¨å°ç£çš„è¡¨é”æ–¹å¼ï¼š
   - ã€Œç›®å‰ã€è€Œéã€Œå½“å‰ã€
   - ã€Œä¹‹å¾Œã€è€Œéã€Œä¹‹åã€
   - ã€Œå› æ­¤ã€è€Œéã€Œæ‰€ä»¥ã€
   - ã€Œç„¶è€Œã€è€Œéã€Œä½†æ˜¯ã€
   - ã€Œè—‰ç”±ã€è€Œéã€Œé€šè¿‡ã€
   - ã€Œæ ¹æ“šã€è€Œéã€ŒæŒ‰ç…§ã€

4. ä½¿ç”¨å°ç£çš„å­¸è¡“ç”¨èªï¼š
   - ã€Œç ”ç©¶ã€è€Œéã€Œç ”è®¨ã€
   - ã€Œæ–¹æ³•ã€è€Œéã€Œæ–¹å¼ã€
   - ã€Œæ¢è¨ã€è€Œéã€Œæ¢è®¨ã€
   - ã€Œå¯¦æ–½ã€è€Œéã€Œå®è¡Œã€
   - ã€Œæˆæ•ˆã€è€Œéã€Œæˆæœã€

5. æ¨™é»ç¬¦è™Ÿä½¿ç”¨ï¼š
   - ä½¿ç”¨ã€Œã€ä½œç‚ºä¸­æ–‡å¼•è™Ÿ
   - ä½¿ç”¨ã€ã€ä½œç‚ºå¼•è™Ÿä¸­çš„å¼•è™Ÿ
   - æ›¸åè™Ÿä½¿ç”¨ã€Šã€‹
   - ç¯‡åè™Ÿä½¿ç”¨ã€ˆã€‰

6. æ–‡ç»æ¢è¨æ’°å¯«è¦ç¯„ï¼š
   - ç¢ºä¿è«–è¿°å®Œæ•´æ€§å’Œé‚è¼¯æ€§
   - é¿å…å…§å®¹é‡è¤‡æˆ–å†—è´…
   - ä¿æŒæ–‡ç« çµæ§‹çš„å¹³è¡¡
   - é©ç•¶åˆ†é…å„éƒ¨åˆ†çš„è«–è¿°æ¯”é‡
   - é‹ç”¨ç²¾ç¢ºçš„è¨­è¨ˆç ”ç©¶å°ˆæ¥­è¡“èª
   - ä¿æŒå®¢è§€çš„å­¸è¡“è«–è¿°èªæ°£
   - å¼·èª¿ç ”ç©¶çš„åŸå‰µæ€§èˆ‡åƒ¹å€¼

7. æ–‡ç»å¼•ç”¨è¦ç¯„ï¼š
   - éµå¾ª APA ç¬¬ä¸ƒç‰ˆæ ¼å¼
   - æ¯å€‹é‡è¦è«–é»éƒ½éœ€è¦æ–‡ç»æ”¯æŒ
   - å¼•ç”¨æ™‚è¦èˆ‡è«–é»ç·Šå¯†çµåˆ
   - é¿å…éåº¦å †ç Œæ–‡ç»
   - ç¢ºä¿å¼•ç”¨çš„æ–‡ç»éƒ½åˆ—åœ¨åƒè€ƒæ–‡ç»æ¸…å–®ä¸­
   - å¼•ç”¨æ ¼å¼ï¼š
     * å–®ä¸€ä½œè€…ï¼šç‹å°æ˜ï¼ˆ2020ï¼‰æˆ–ï¼ˆç‹å°æ˜ï¼Œ2020ï¼‰
     * å…©ä½ä½œè€…ï¼šç‹å°æ˜èˆ‡æå¤§è¯ï¼ˆ2020ï¼‰æˆ–ï¼ˆç‹å°æ˜ã€æå¤§è¯ï¼Œ2020ï¼‰
     * ä¸‰ä½ä»¥ä¸Šä½œè€…ï¼šç‹å°æ˜ç­‰äººï¼ˆ2020ï¼‰æˆ–ï¼ˆç‹å°æ˜ç­‰äººï¼Œ2020ï¼‰
     * è‹±æ–‡æ–‡ç»æ¯”ç…§ä¸­æ–‡æ ¼å¼ï¼Œä½œè€…å§“æ°å¤§å¯«"""

    # æº–å‚™æ–‡ç»è³‡æ–™
    literature_data = []
    for lit in literature_list:
        literature_data.append({
            'citation': lit['citation'],
            'content': lit['abstract'],
            'relevance': lit['relevance'],
            'contribution': lit['contribution']
        })

    user_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹æ–‡ç»è³‡æ–™ï¼Œæ’°å¯«ã€Œ{section_title}ã€ç« ç¯€çš„æ–‡ç»æ¢è¨å…§å®¹ã€‚

æ–‡ç»è³‡æ–™ï¼š
{json.dumps(literature_data, ensure_ascii=False, indent=2)}

ã€å¯«ä½œè¦æ±‚ã€‘

1. å­—æ•¸èˆ‡å“è³ªè¦æ±‚ï¼š
   - æœ¬ç« ç¯€æ–‡å­—è‡³å°‘ 1200 å­—ï¼ˆå¿…é ˆè¶…éæ­¤å­—æ•¸ï¼Œä¸å¾—ä½æ–¼ï¼‰
   - ç¢ºä¿è«–è¿°å®Œæ•´ä¸”æ·±å…¥
   - é¿å…ç©ºæ³›æˆ–è¡¨é¢çš„æè¿°
   - æ¯å€‹è«–é»éƒ½è¦æœ‰å……åˆ†çš„æ–‡ç»æ”¯æŒ
   - é©ç•¶å¼•ç”¨æ–‡ç»ä¸­çš„å…·é«”ç ”ç©¶ç™¼ç¾

2. å…§å®¹ç™¼å±•è¦æ±‚ï¼š
   - æ·±å…¥åˆ†ææ–‡ç»ä¸­çš„ç†è«–è§€é»
   - æ¯”è¼ƒä¸åŒç ”ç©¶çš„æ–¹æ³•èˆ‡ç™¼ç¾
   - æ•´åˆç›¸ä¼¼è§€é»ï¼Œå°æ¯”ç›¸ç•°è§€é»
   - æŒ‡å‡ºç ”ç©¶è¶¨å‹¢èˆ‡ç™¼å±•è„ˆçµ¡
   - é€£çµç†è«–åŸºç¤èˆ‡å¯¦å‹™æ‡‰ç”¨
   - çªé¡¯é‡è¦ç ”ç©¶ç™¼ç¾èˆ‡è²¢ç»

3. è«–è¿°çµæ§‹è¦æ±‚ï¼š
   - ä»¥é€£è²«ä¸”å®Œæ•´çš„æ–¹å¼å‘ˆç¾
   - ç¢ºä¿æ®µè½ä¹‹é–“çš„é‚è¼¯æµæš¢æ€§
   - é©ç•¶é‹ç”¨è½‰æŠ˜èªå¥é€£æ¥å„å€‹é‡é»
   - ç”±æ·ºå…¥æ·±ï¼Œå¾ªåºæ¼¸é€²åœ°å±•é–‹è«–è¿°
   - é©åº¦åˆ†æ®µä»¥å¢åŠ å¯è®€æ€§

4. æ–‡ç»æ•´åˆè¦æ±‚ï¼š
   - ç¢ºä¿å¼•ç”¨çš„æ–‡ç»ç›¸äº’å‘¼æ‡‰
   - å»ºç«‹æ–‡ç»ä¹‹é–“çš„å°è©±é—œä¿‚
   - é©ç•¶æ¯”è¼ƒä¸åŒç ”ç©¶çš„è§€é»
   - æŒ‡å‡ºæ–‡ç»é–“çš„å…±åŒç™¼ç¾
   - åˆ†æç›¸ç•°è§€é»çš„åŸå› 

5. å­¸è¡“åš´è¬¹åº¦ï¼š
   - ç¢ºä¿æ¯å€‹è«–é»éƒ½æœ‰æ–‡ç»æ”¯æŒ
   - æº–ç¢ºå¼•ç”¨ç ”ç©¶ç™¼ç¾å’Œçµè«–
   - å®¢è§€å‘ˆç¾ä¸åŒè§€é»
   - é©ç•¶è©•æç ”ç©¶é™åˆ¶
   - æŒ‡å‡ºæœªä¾†ç ”ç©¶æ–¹å‘

6. èˆ‡ç ”ç©¶ç›®çš„çš„é€£çµï¼š
   - ç¢ºä¿æ–‡ç»æ¢è¨æ–¹å‘èˆ‡ç ”ç©¶ç›®çš„ä¸€è‡´
   - é¸æ“‡æ€§å¼·èª¿èˆ‡ç ”ç©¶ç›¸é—œçš„æ–‡ç»è§€é»
   - åˆ†ææ–‡ç»å°ç ”ç©¶å•é¡Œçš„è²¢ç»
   - æŒ‡å‡ºæ–‡ç»ä¸­çš„ç†è«–ç¼ºå£
   - èªªæ˜æœ¬ç ”ç©¶çš„æ½›åœ¨è²¢ç»

è«‹æä¾›ï¼š
1. å®Œæ•´çš„æ–‡ç»æ¢è¨å…§å®¹ï¼ˆè‡³å°‘ 1200 å­—ï¼Œå¯è¦–å…§å®¹éœ€è¦å¢åŠ å­—æ•¸ï¼‰
2. è©²ç« ç¯€ä½¿ç”¨çš„åƒè€ƒæ–‡ç» APA æ ¼å¼åˆ—è¡¨

å›è¦†æ ¼å¼ï¼š
===æ–‡ç»æ¢è¨===
[1200å­—ä»¥ä¸Šçš„æ–‡ç»æ¢è¨å…§å®¹]

===åƒè€ƒæ–‡ç»===
[APAæ ¼å¼åƒè€ƒæ–‡ç»åˆ—è¡¨]"""

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=3000
        )
        content = response.choices[0].message.content.strip()
        
        # åˆ†å‰²å…§å®¹å’Œåƒè€ƒæ–‡ç»
        parts = content.split('===åƒè€ƒæ–‡ç»===')
        review_content = parts[0].replace('===æ–‡ç»æ¢è¨===', '').strip()
        references = parts[1].strip() if len(parts) > 1 else ""
        
        return {
            'content': review_content,
            'references': references
        }
    except Exception as e:
        st.error(f"ç”Ÿæˆæ–‡ç»æ¢è¨å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def load_research_purpose():
    """è®€å–å„²å­˜çš„ç ”ç©¶ç›®çš„å…§å®¹"""
    try:
        with open('.research_purpose.tmp', 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('research_purpose', '')
    except (FileNotFoundError, json.JSONDecodeError):
        return ''

def main():
    st.title("ğŸ“š ç ”ç©¶æ–‡ç»æ¶æ§‹åˆ†æå·¥å…·")
    st.write("æœ¬å·¥å…·å¯ä»¥å”åŠ©æ‚¨æ ¹æ“šç ”ç©¶ç›®çš„è¦åŠƒæ–‡ç»æ¢è¨æ¶æ§‹ï¼Œä¸¦æä¾›é©åˆçš„æœå°‹é—œéµå­—ã€‚")
    
    # åˆå§‹åŒ– session state
    if 'sections' not in st.session_state:
        st.session_state.sections = None
    if 'literature_data' not in st.session_state:
        st.session_state.literature_data = {}
    if 'literature_reviews' not in st.session_state:
        st.session_state.literature_reviews = {}
    
    # è®€å–å…ˆå‰ç”¢ç”Ÿçš„ç ”ç©¶ç›®çš„
    saved_purpose = load_research_purpose()
    
    # è¼¸å…¥å€åŸŸ
    research_purpose = st.text_area(
        "è«‹è²¼å…¥æ‚¨çš„ç ”ç©¶ç›®çš„å…§å®¹",
        value=saved_purpose,  # ä½¿ç”¨å„²å­˜çš„å…§å®¹ä½œç‚ºé è¨­å€¼
        height=200,
        help="å°‡æ‚¨æ’°å¯«çš„ç ”ç©¶ç›®çš„å…§å®¹è²¼åœ¨é€™è£¡"
    )
    
    if st.button("ç”¢ç”Ÿæ–‡ç»æ¢è¨æ¶æ§‹"):
        if not research_purpose:
            st.error("è«‹å…ˆè¼¸å…¥ç ”ç©¶ç›®çš„å…§å®¹")
            return
            
        with st.spinner("æ­£åœ¨åˆ†æç ”ç©¶ç›®çš„ä¸¦ç”¢ç”Ÿæ¶æ§‹..."):
            result = analyze_research_purpose(research_purpose)
            if result and 'sections' in result:
                st.session_state.sections = result['sections']
                st.session_state.literature_data = {
                    section['title_zh']: {'literature': []}
                    for section in result['sections']
                }
    
    # é¡¯ç¤ºçµæœå’Œæ”¶é›†æ–‡ç»
    if st.session_state.sections:
        for section in st.session_state.sections:
            st.markdown("---")
            st.markdown(f"## {section['title_zh']}")
            st.markdown(f"**é‡é»èªªæ˜ï¼š**\n{section['description']}")
            
            st.markdown("**å»ºè­°æœå°‹å­—ä¸²ï¼š**")
            for search in section['search_queries']:
                st.markdown(f"- {search['focus']}:")
                st.code(search['query'], language="text")
            
            # æ–‡ç»æ”¶é›†å€åŸŸ
            st.markdown("### ğŸ“‘ æ–‡ç»æ”¶é›†")
            
            # æ–‡ç»è¼¸å…¥
            new_literature = st.text_area(
                "è«‹è²¼å…¥å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼èˆ‡æ‘˜è¦ï¼ˆæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œï¼‰",
                key=f"literature_{section['title_zh']}",
                height=400,
                help="å¾ SciSpace è¤‡è£½å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦ï¼Œæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œ"
            )
            
            col1, col2 = st.columns(2)
            
            # æ–°å¢æ–‡ç»æŒ‰éˆ•
            with col1:
                if st.button(f"åˆ†æä¸¦æ–°å¢æ–‡ç»åˆ°ã€Œ{section['title_zh']}ã€", key=f"add_{section['title_zh']}"):
                    if new_literature.strip():
                        with st.spinner("æ­£åœ¨åˆ†ææ–‡ç»å…§å®¹..."):
                            analysis_results = analyze_multiple_literature(section['title_zh'], new_literature)
                            if analysis_results:
                                st.session_state.literature_data[section['title_zh']]['literature'].extend(analysis_results)
                                st.success(f"å·²æˆåŠŸåˆ†æä¸¦æ–°å¢ {len(analysis_results)} ç¯‡æ–‡ç»")
            
            # ç”¢ç”Ÿæ–‡ç»æ¢è¨æŒ‰éˆ•
            with col2:
                if st.button(f"ç”¢ç”Ÿã€Œ{section['title_zh']}ã€çš„æ–‡ç»æ¢è¨", key=f"review_{section['title_zh']}"):
                    if st.session_state.literature_data[section['title_zh']]['literature']:
                        with st.spinner("æ­£åœ¨ç”¢ç”Ÿæ–‡ç»æ¢è¨å…§å®¹..."):
                            review_result = generate_literature_review(
                                section['title_zh'],
                                st.session_state.literature_data[section['title_zh']]['literature']
                            )
                            if review_result:
                                st.session_state.literature_reviews[section['title_zh']] = review_result
                                st.success("å·²æˆåŠŸç”¢ç”Ÿæ–‡ç»æ¢è¨å…§å®¹")
                    else:
                        st.warning("è«‹å…ˆæ–°å¢æ–‡ç»å†ç”¢ç”Ÿæ–‡ç»æ¢è¨")
            
            # é¡¯ç¤ºå·²æ”¶é›†çš„æ–‡ç»
            if st.session_state.literature_data[section['title_zh']]['literature']:
                st.markdown("#### å·²æ”¶é›†çš„æ–‡ç»")
                for i, lit in enumerate(st.session_state.literature_data[section['title_zh']]['literature']):
                    with st.expander(f"æ–‡ç» {i+1}"):
                        st.markdown("**å¼•ç”¨æ ¼å¼ï¼š**")
                        st.markdown(lit['citation'])
                        st.markdown("**æ‘˜è¦ï¼š**")
                        st.markdown(lit['abstract'])
                        st.markdown("**èˆ‡æœ¬ç« ç¯€çš„ç›¸é—œæ€§ï¼š**")
                        st.markdown(lit['relevance'])
                        st.markdown("**ä¸»è¦è²¢ç»ï¼š**")
                        st.markdown(lit['contribution'])
                        st.markdown("**å»ºè­°å¼•ç”¨æ–¹å¼ï¼š**")
                        st.markdown(lit['usage_suggestion'])
            
            # é¡¯ç¤ºæ–‡ç»æ¢è¨å…§å®¹
            if section['title_zh'] in st.session_state.literature_reviews:
                review = st.session_state.literature_reviews[section['title_zh']]
                with st.expander("ğŸ“ æ–‡ç»æ¢è¨å…§å®¹", expanded=True):
                    st.markdown("### æ–‡ç»æ¢è¨")
                    st.markdown(review['content'])
                    
                    st.markdown("### åƒè€ƒæ–‡ç»")
                    st.markdown(review['references'])
        
        # æä¾›å¯¦ç”¨é€£çµ
        st.markdown("---")
        st.markdown("""
        ### ğŸ“– æ“ä½œæç¤º
        1. ä½¿ç”¨ä¸Šæ–¹çš„æœå°‹å­—ä¸²åœ¨ [SciSpace](https://typeset.io/) æœå°‹ç›¸é—œæ–‡ç»
        2. å¾æœå°‹çµæœä¸­è¤‡è£½å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦
        3. å°‡è¤‡è£½çš„å…§å®¹ç›´æ¥è²¼åˆ°å°æ‡‰ç« ç¯€çš„è¼¸å…¥æ¡†ä¸­ï¼ˆæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œï¼‰
        4. é»é¸ã€Œåˆ†æä¸¦æ–°å¢æ–‡ç»ã€æŒ‰éˆ•ï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†æä¸¦æ•´ç†æ‰€æœ‰æ–‡ç»å…§å®¹
        5. æ”¶é›†è¶³å¤ æ–‡ç»å¾Œï¼Œé»é¸ã€Œç”¢ç”Ÿæ–‡ç»æ¢è¨ã€æŒ‰éˆ•ç”¢ç”Ÿè©²ç« ç¯€çš„æ–‡ç»æ¢è¨å…§å®¹
        6. å»ºè­°æ¯å€‹ç« ç¯€è‡³å°‘æ”¶é›† 3-5 ç¯‡ç›¸é—œæ–‡ç»
        """)

if __name__ == "__main__":
    main() 