import streamlit as st
import openai
import os
from dotenv import load_dotenv
import json
import re

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def extract_json_from_response(content):
    """å¾å›æ‡‰ä¸­æå– JSON å…§å®¹"""
    # å˜—è©¦æ‰¾å‡º JSON å…§å®¹çš„é–‹å§‹å’ŒçµæŸ
    try:
        # æ‰¾å‡ºç¬¬ä¸€å€‹ { å’Œæœ€å¾Œä¸€å€‹ } çš„ä½ç½®
        start = content.find('{')
        end = content.rfind('}') + 1
        if start != -1 and end != -1:
            json_str = content[start:end]
            return json.loads(json_str)
    except:
        pass
    return None

def analyze_research_purpose(research_purpose):
    """åˆ†æç ”ç©¶ç›®çš„ä¸¦ç”Ÿæˆæ–‡ç»æ¢è¨æ¶æ§‹"""
    system_prompt = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç ”ç©¶æ–¹æ³•å°ˆå®¶ï¼Œæ“…é•·è¦åŠƒæ–‡ç»æ¢è¨æ¶æ§‹ã€‚
è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼Œä¸è¦åŠ å…¥ä»»ä½•å…¶ä»–èªªæ˜æ–‡å­—ï¼š
{
    "sections": [
        {
            "title": "ä¸­æ–‡ç« ç¯€æ¨™é¡Œ",
            "description": "æœ¬ç« ç¯€æ‡‰è©²æ¢è¨çš„é‡é»",
            "search_strings": [
                {
                    "description": "æœå°‹é‡é»æè¿°",
                    "query": "å®Œæ•´çš„è‹±æ–‡æœå°‹å­—ä¸²æˆ–è‡ªç„¶èªå¥"
                }
            ]
        }
    ]
}"""

    user_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ç ”ç©¶ç›®çš„ï¼Œåˆ†æä¸¦æä¾›ï¼š
1. 3-5å€‹é©åˆçš„æ–‡ç»æ¢è¨ç« ç¯€æ¨™é¡Œ
2. æ¯å€‹æ¨™é¡Œçš„é‡é»èªªæ˜
3. é‡å°æ¯å€‹æ¨™é¡Œæä¾› 2-3 å€‹è‹±æ–‡æœå°‹å­—ä¸²ï¼Œé€™äº›å­—ä¸²æ‡‰è©²è¦ï¼š
   - å¯ä»¥ç›´æ¥è¤‡è£½åˆ° SciSpace æœå°‹æ¡†ä½¿ç”¨
   - ä½¿ç”¨å®Œæ•´çš„è‹±æ–‡è‡ªç„¶èªå¥æˆ–é—œéµå­—çµ„åˆ
   - åŒ…å«è©²ä¸»é¡Œæœ€é‡è¦çš„æœå°‹é‡é»
   - è€ƒæ…®è¿‘äº”å¹´çš„ç ”ç©¶è¶¨å‹¢

ç ”ç©¶ç›®çš„å…§å®¹ï¼š
{research_purpose}

è«‹å‹™å¿…æŒ‰ç…§ç³»çµ±æç¤ºçš„ JSON æ ¼å¼å›è¦†ï¼Œä¸è¦åŠ å…¥ä»»ä½•é¡å¤–èªªæ˜ã€‚"""
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        content = response.choices[0].message.content.strip()
        
        # å˜—è©¦ç›´æ¥è§£æ
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±æ•—ï¼Œå˜—è©¦æå– JSON éƒ¨åˆ†
            result = extract_json_from_response(content)
            if result:
                return result
            else:
                st.error("ç„¡æ³•è§£æå›æ‡‰ç‚º JSON æ ¼å¼")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def analyze_multiple_literature(section_title, literature_texts):
    """åˆ†æå¤šç¯‡æ–‡ç»å…§å®¹ä¸¦ç”Ÿæˆæ‘˜è¦åˆ†æ"""
    system_prompt = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ–‡ç»åˆ†æå°ˆå®¶ï¼Œè«‹å”åŠ©åˆ†æè¼¸å…¥çš„å¤šç¯‡æ–‡ç»å…§å®¹ã€‚
å¾è¼¸å…¥çš„æ–‡å­—ä¸­è­˜åˆ¥å‡ºæ¯ç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦å…§å®¹ï¼Œä¸¦é€²è¡Œåˆ†ææ•´ç†ã€‚
æ¯ç¯‡æ–‡ç»ä¹‹é–“æ‡‰è©²æ˜¯ç”¨é€£çºŒå…©å€‹æ›è¡Œç¬¦è™Ÿåˆ†éš”ã€‚"""

    user_prompt = f"""è«‹åˆ†æä»¥ä¸‹å¤šç¯‡æ–‡ç»å…§å®¹ï¼Œä¸¦æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ•´ç†æ¯ä¸€ç¯‡ï¼š
1. è­˜åˆ¥ä¸¦æå–æ¯ç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼
2. æå–æ¯ç¯‡æ–‡ç»çš„æ‘˜è¦å…§å®¹
3. åˆ†ææ¯ç¯‡æ–‡ç»èˆ‡ã€Œ{section_title}ã€ç« ç¯€çš„ç›¸é—œæ€§
4. æä¾›æ¯ç¯‡æ–‡ç»å°è©²ç« ç¯€çš„ä¸»è¦è²¢ç»
5. å»ºè­°åœ¨æ–‡ç»å›é¡§ä¸­å¦‚ä½•å¼•ç”¨æ¯ç¯‡æ–‡ç»

è¼¸å…¥å…§å®¹ï¼š
{literature_texts}

è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼ŒåŒ…å«æ‰€æœ‰æ–‡ç»çš„åˆ†æçµæœï¼š
{{
    "literature": [
        {{
            "citation": "APAå¼•ç”¨æ ¼å¼",
            "abstract": "æ‘˜è¦å…§å®¹",
            "relevance": "èˆ‡ç« ç¯€çš„ç›¸é—œæ€§åˆ†æ",
            "contribution": "å°ç« ç¯€çš„ä¸»è¦è²¢ç»",
            "usage_suggestion": "åœ¨æ–‡ç»å›é¡§ä¸­çš„å¼•ç”¨å»ºè­°"
        }}
    ]
}}"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        content = response.choices[0].message.content.strip()
        
        try:
            result = json.loads(content)
            if 'literature' in result:
                return result['literature']
            return None
        except json.JSONDecodeError:
            result = extract_json_from_response(content)
            if result and 'literature' in result:
                return result['literature']
            else:
                st.error("ç„¡æ³•è§£ææ–‡ç»åˆ†æçµæœ")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"åˆ†ææ–‡ç»æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def generate_literature_review(section_title, literature_list):
    """ç”Ÿæˆæ–‡ç»æ¢è¨å…§å®¹"""
    system_prompt = """ä½ æ˜¯ä¸€ä½æ·±è€•æ–¼ç ”ç©¶é ˜åŸŸçš„å°ˆæ¥­å­¸è¡“ç ”ç©¶è€…ï¼Œæ“…é•·æ•´åˆæ–‡ç»ä¸¦æ’°å¯«å…·æœ‰æ·±åº¦çš„æ–‡ç»æ¢è¨ã€‚åœ¨æ’°å¯«æ™‚ï¼š
1. æ ¹æ“šç ”ç©¶ä¸»é¡Œèª¿æ•´å°ˆæ¥­è¡“èªå’Œè«–è¿°æ–¹å¼
2. è‡ªç„¶åœ°èå…¥ç ”ç©¶è€…çš„è§€å¯Ÿèˆ‡ç¶“é©—
3. å±•ç¾æ·±å…¥çš„æ€è€ƒéç¨‹å’Œé‚è¼¯æ¨æ¼”
4. ç¶­æŒå­¸è¡“åš´è¬¹æ€§å’Œå‰µæ–°æ€ç¶­
5. ç¢ºä¿æ–‡ç« çµæ§‹å®Œæ•´ä¸”è«–è¿°æµæš¢"""

    user_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹æ–‡ç»è³‡æ–™ï¼Œç‚ºã€Œ{section_title}ã€ç« ç¯€æ’°å¯«æ–‡ç»æ¢è¨å…§å®¹ã€‚

æ–‡ç»è³‡æ–™ï¼š
{json.dumps(literature_list, ensure_ascii=False, indent=2)}

ã€å¯«ä½œè¦æ±‚ã€‘
1. æ–‡ç« é¢¨æ ¼ï¼š
   - é‹ç”¨ç¬¬ä¸€äººç¨±æ•˜è¿°ï¼Œå±•ç¾ç ”ç©¶è€…çš„å°ˆæ¥­æ´å¯Ÿ
   - ä¿æŒå­¸è¡“åš´è¬¹æ€§çš„åŒæ™‚ï¼Œèå…¥å€‹äººè§€é»å’Œç¶“é©—
   - æ®µè½ä¹‹é–“è¦æœ‰è‡ªç„¶çš„é‚è¼¯æ¨å±•
   - é¿å…éæ–¼åˆ¶å¼åŒ–çš„è¡¨é”æ–¹å¼

2. è«–è¿°æ–¹å¼ï¼š
   - å¾æ–‡ç»å›é¡§ä¸­æ‰¾å‡ºç ”ç©¶è¶¨å‹¢å’Œç¼ºå£
   - çµåˆä¸åŒæ–‡ç»çš„è§€é»é€²è¡Œæ¯”è¼ƒå’Œæ•´åˆ
   - å±•ç¾æ€è€ƒçš„æ·±åº¦èˆ‡å»£åº¦
   - é©åº¦èå…¥é ˜åŸŸå°ˆæ¥­è¡“èª

3. èªè¨€è¡¨é”ï¼š
   - ä½¿ç”¨æµæš¢ä¸”å°ˆæ¥­çš„å­¸è¡“ç”¨èª
   - é¿å…éåº¦å †ç Œæ–‡ç»
   - ä¿æŒè«–è¿°çš„é€£è²«æ€§å’Œé‚è¼¯æ€§
   - é©æ™‚ä½¿ç”¨è½‰æŠ˜èªå¥å¢åŠ æ–‡ç« æµæš¢åº¦

ã€å…§å®¹æ¶æ§‹ã€‘ï¼ˆè‡³å°‘ 800 å­—ï¼‰ï¼š

1. ç ”ç©¶è„ˆçµ¡èˆ‡è¶¨å‹¢åˆ†æï¼ˆç´„ 300 å­—ï¼‰ï¼š
   - åˆ†æè©²é ˜åŸŸçš„ç ”ç©¶ç™¼å±•è„ˆçµ¡
   - æŒ‡å‡ºä¸»è¦ç ”ç©¶æ–¹å‘å’Œè¶¨å‹¢
   - æ•´åˆä¸åŒå­¸è€…çš„è§€é»
   - çªé¡¯é‡è¦çš„ç ”ç©¶ç™¼ç¾

2. ç†è«–èˆ‡å¯¦å‹™çš„æ•´åˆï¼ˆç´„ 300 å­—ï¼‰ï¼š
   - åˆ†æç†è«–åŸºç¤å’Œå¯¦å‹™æ‡‰ç”¨
   - æ¯”è¼ƒä¸åŒç ”ç©¶çš„æ–¹æ³•å’Œç™¼ç¾
   - è¨è«–ç ”ç©¶çµæœçš„å¯¦å‹™æ„æ¶µ
   - æŒ‡å‡ºç†è«–èˆ‡å¯¦å‹™çš„é€£çµ

3. ç ”ç©¶ç¼ºå£èˆ‡æœªä¾†æ–¹å‘ï¼ˆç´„ 200 å­—ï¼‰ï¼š
   - æ­¸ç´ç›®å‰ç ”ç©¶çš„é™åˆ¶
   - æŒ‡å‡ºå€¼å¾—æ·±å…¥æ¢è¨çš„è­°é¡Œ
   - æå‡ºå¯èƒ½çš„ç ”ç©¶æ–¹å‘
   - èªªæ˜ç ”ç©¶åƒ¹å€¼å’Œé‡è¦æ€§

è«‹ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼š
{
    "literature_review": "å®Œæ•´çš„æ–‡ç»æ¢è¨å…§å®¹",
    "references": [
        "APAæ ¼å¼çš„åƒè€ƒæ–‡ç»åˆ—è¡¨"
    ],
    "key_findings": [
        "é‡è¦ç™¼ç¾1",
        "é‡è¦ç™¼ç¾2"
    ],
    "research_gaps": [
        "ç ”ç©¶ç¼ºå£1",
        "ç ”ç©¶ç¼ºå£2"
    ]
}

æ³¨æ„äº‹é …ï¼š
1. æ–‡ç»å¼•ç”¨è¦è‡ªç„¶åœ°èå…¥è«–è¿°ä¸­ï¼ˆä½¿ç”¨ APA æ ¼å¼ï¼‰
2. ç¢ºä¿ä¸åŒæ®µè½ä¹‹é–“çš„é‚è¼¯é€£è²«æ€§
3. é©ç•¶ä½¿ç”¨è½‰æŠ˜èªå¥å¢åŠ æ–‡ç« æµæš¢åº¦
4. åœ¨ä¿æŒå®¢è§€æ€§çš„åŒæ™‚ï¼Œä¹Ÿè¦å±•ç¾å€‹äººçš„å°ˆæ¥­åˆ¤æ–·"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        content = response.choices[0].message.content.strip()
        
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            result = extract_json_from_response(content)
            if result:
                return result
            else:
                st.error("ç„¡æ³•è§£ææ–‡ç»æ¢è¨ç”Ÿæˆçµæœ")
                st.text_area("åŸå§‹å›æ‡‰å…§å®¹", content, height=200)
                return None
    except Exception as e:
        st.error(f"ç”Ÿæˆæ–‡ç»æ¢è¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def main():
    st.title("ğŸ“š ç ”ç©¶æ–‡ç»æ¶æ§‹åˆ†æå·¥å…·")
    st.write("æœ¬å·¥å…·å¯ä»¥å”åŠ©æ‚¨æ ¹æ“šç ”ç©¶ç›®çš„è¦åŠƒæ–‡ç»æ¢è¨æ¶æ§‹ï¼Œä¸¦æä¾›é©åˆçš„æœå°‹é—œéµå­—ã€‚")
    
    # åˆå§‹åŒ– session state
    if 'sections' not in st.session_state:
        st.session_state.sections = None
    if 'literature_data' not in st.session_state:
        st.session_state.literature_data = {}
    if 'literature_reviews' not in st.session_state:
        st.session_state.literature_reviews = {}
    
    # è¼¸å…¥å€åŸŸ
    research_purpose = st.text_area(
        "è«‹è²¼å…¥æ‚¨çš„ç ”ç©¶ç›®çš„å…§å®¹",
        height=200,
        help="å°‡æ‚¨ç”Ÿæˆçš„ç ”ç©¶ç›®çš„å…§å®¹è²¼åœ¨é€™è£¡"
    )
    
    if st.button("ç”Ÿæˆæ–‡ç»æ¢è¨æ¶æ§‹"):
        if not research_purpose:
            st.error("è«‹å…ˆè¼¸å…¥ç ”ç©¶ç›®çš„å…§å®¹")
            return
            
        with st.spinner("æ­£åœ¨åˆ†æç ”ç©¶ç›®çš„ä¸¦ç”Ÿæˆæ¶æ§‹..."):
            result = analyze_research_purpose(research_purpose)
            if result and 'sections' in result:
                st.session_state.sections = result['sections']
                st.session_state.literature_data = {
                    section['title']: {'literature': []}
                    for section in result['sections']
                }
    
    # é¡¯ç¤ºçµæœå’Œæ”¶é›†æ–‡ç»
    if st.session_state.sections:
        for section in st.session_state.sections:
            st.markdown("---")
            st.markdown(f"## {section['title']}")
            st.markdown(f"**é‡é»èªªæ˜ï¼š**\n{section['description']}")
            
            st.markdown("**å»ºè­°æœå°‹å­—ä¸²ï¼š**")
            for search in section['search_strings']:
                st.markdown(f"- {search['description']}:")
                st.code(search['query'], language="text")
            
            # æ–‡ç»æ”¶é›†å€åŸŸ
            st.markdown("### ğŸ“‘ æ–‡ç»æ”¶é›†")
            
            # æ–‡ç»è¼¸å…¥
            new_literature = st.text_area(
                "è«‹è²¼å…¥å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼èˆ‡æ‘˜è¦ï¼ˆæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œï¼‰",
                key=f"literature_{section['title']}",
                height=400,
                help="å¾ SciSpace è¤‡è£½å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦ï¼Œæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œ"
            )
            
            col1, col2 = st.columns(2)
            
            # æ–°å¢æ–‡ç»æŒ‰éˆ•
            with col1:
                if st.button(f"åˆ†æä¸¦æ–°å¢æ–‡ç»åˆ°ã€Œ{section['title']}ã€", key=f"add_{section['title']}"):
                    if new_literature.strip():
                        with st.spinner("æ­£åœ¨åˆ†ææ–‡ç»å…§å®¹..."):
                            analysis_results = analyze_multiple_literature(section['title'], new_literature)
                            if analysis_results:
                                st.session_state.literature_data[section['title']]['literature'].extend(analysis_results)
                                st.success(f"å·²æˆåŠŸåˆ†æä¸¦æ–°å¢ {len(analysis_results)} ç¯‡æ–‡ç»")
            
            # ç”Ÿæˆæ–‡ç»æ¢è¨æŒ‰éˆ•
            with col2:
                if st.button(f"ç”Ÿæˆã€Œ{section['title']}ã€çš„æ–‡ç»æ¢è¨", key=f"review_{section['title']}"):
                    if st.session_state.literature_data[section['title']]['literature']:
                        with st.spinner("æ­£åœ¨ç”Ÿæˆæ–‡ç»æ¢è¨å…§å®¹..."):
                            review_result = generate_literature_review(
                                section['title'],
                                st.session_state.literature_data[section['title']]['literature']
                            )
                            if review_result:
                                st.session_state.literature_reviews[section['title']] = review_result
                                st.success("å·²æˆåŠŸç”Ÿæˆæ–‡ç»æ¢è¨å…§å®¹")
                    else:
                        st.warning("è«‹å…ˆæ–°å¢æ–‡ç»å†ç”Ÿæˆæ–‡ç»æ¢è¨")
            
            # é¡¯ç¤ºå·²æ”¶é›†çš„æ–‡ç»
            if st.session_state.literature_data[section['title']]['literature']:
                st.markdown("#### å·²æ”¶é›†çš„æ–‡ç»")
                for i, lit in enumerate(st.session_state.literature_data[section['title']]['literature']):
                    with st.expander(f"æ–‡ç» {i+1}"):
                        st.markdown("**å¼•ç”¨æ ¼å¼ï¼š**")
                        st.markdown(lit['citation'])
                        st.markdown("**æ‘˜è¦ï¼š**")
                        st.markdown(lit['abstract'])
                        st.markdown("**èˆ‡æœ¬ç« ç¯€çš„ç›¸é—œæ€§ï¼š**")
                        st.markdown(lit['relevance'])
                        st.markdown("**ä¸»è¦è²¢ç»ï¼š**")
                        st.markdown(lit['contribution'])
                        st.markdown("**å»ºè­°å¼•ç”¨æ–¹å¼ï¼š**")
                        st.markdown(lit['usage_suggestion'])
            
            # é¡¯ç¤ºæ–‡ç»æ¢è¨å…§å®¹
            if section['title'] in st.session_state.literature_reviews:
                review = st.session_state.literature_reviews[section['title']]
                with st.expander("ğŸ“ æ–‡ç»æ¢è¨å…§å®¹", expanded=True):
                    st.markdown("### æ–‡ç»æ¢è¨")
                    st.markdown(review['literature_review'])
                    
                    st.markdown("### é‡è¦ç™¼ç¾")
                    for finding in review['key_findings']:
                        st.markdown(f"- {finding}")
                    
                    st.markdown("### ç ”ç©¶ç¼ºå£")
                    for gap in review['research_gaps']:
                        st.markdown(f"- {gap}")
                    
                    st.markdown("### åƒè€ƒæ–‡ç»")
                    for ref in review['references']:
                        st.markdown(f"- {ref}")
        
        # æä¾›å¯¦ç”¨é€£çµ
        st.markdown("---")
        st.markdown("""
        ### ğŸ“– æ“ä½œæç¤º
        1. ä½¿ç”¨ä¸Šæ–¹çš„æœå°‹å­—ä¸²åœ¨ [SciSpace](https://typeset.io/) æœå°‹ç›¸é—œæ–‡ç»
        2. å¾æœå°‹çµæœä¸­è¤‡è£½å¤šç¯‡æ–‡ç»çš„ APA å¼•ç”¨æ ¼å¼å’Œæ‘˜è¦
        3. å°‡è¤‡è£½çš„å…§å®¹ç›´æ¥è²¼åˆ°å°æ‡‰ç« ç¯€çš„è¼¸å…¥æ¡†ä¸­ï¼ˆæ¯ç¯‡æ–‡ç»ä¹‹é–“è«‹ç©ºä¸€è¡Œï¼‰
        4. é»æ“Šã€Œåˆ†æä¸¦æ–°å¢æ–‡ç»ã€æŒ‰éˆ•ï¼Œç³»çµ±æœƒè‡ªå‹•åˆ†æä¸¦æ•´ç†æ‰€æœ‰æ–‡ç»å…§å®¹
        5. æ”¶é›†è¶³å¤ æ–‡ç»å¾Œï¼Œé»æ“Šã€Œç”Ÿæˆæ–‡ç»æ¢è¨ã€æŒ‰éˆ•ç”¢ç”Ÿè©²ç« ç¯€çš„æ–‡ç»æ¢è¨å…§å®¹
        6. å»ºè­°æ¯å€‹ç« ç¯€è‡³å°‘æ”¶é›† 3-5 ç¯‡ç›¸é—œæ–‡ç»
        """)

if __name__ == "__main__":
    main() 