import streamlit as st
import os
import openai
from dotenv import load_dotenv
import json
import time
import subprocess

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­ç½® OpenAI API é‡‘é‘°
api_key = os.getenv('OPENAI_API_KEY')
if api_key:
    openai.api_key = api_key
else:
    openai.api_key = None

def generate_keywords(topic, content):
    """ä½¿ç”¨ OpenAI ç”Ÿæˆé—œéµå­—"""
    if not openai.api_key:
        st.error("OpenAI API é‡‘é‘°æœªè¨­ç½®ï¼")
        return []

    prompt = f"""
è«‹å¾ä»¥ä¸‹ç ”ç©¶ä¸»é¡Œå’Œå…§å®¹ä¸­ï¼Œä»¥å°ç£å­¸è¡“ç•Œå¸¸ç”¨çš„ç¹é«”ä¸­æ–‡è¡“èªæå–10å€‹æœ€é‡è¦çš„é—œéµè©ï¼ˆè«‹åŒæ™‚æä¾›ä¸­è‹±å°ç…§ï¼‰ï¼š

ç ”ç©¶ä¸»é¡Œï¼š
{topic}

ç ”ç©¶å…§å®¹ï¼š
{content}

è«‹ä¾ç…§ä»¥ä¸‹é¡åˆ¥æä¾›é—œéµè©ï¼š
1. ç ”ç©¶é ˜åŸŸç›¸é—œï¼ˆå¦‚ï¼šç”¢å“è¨­è¨ˆ / Product Designï¼‰
2. ç ”ç©¶æ–¹æ³•ç›¸é—œï¼ˆå¦‚ï¼šè¨­è¨ˆæ€è€ƒ / Design Thinkingï¼‰
3. ç ”ç©¶å°è±¡ç›¸é—œï¼ˆå¦‚ï¼šä½¿ç”¨è€…ç¶“é©— / User Experienceï¼‰
4. ç†è«–æ¡†æ¶ç›¸é—œï¼ˆå¦‚ï¼šäººæ©Ÿäº’å‹• / Human-Computer Interactionï¼‰
5. é æœŸæˆæœç›¸é—œï¼ˆå¦‚ï¼šè¨­è¨ˆæº–å‰‡ / Design Guidelinesï¼‰

è«‹ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å›è¦†ï¼Œæ¯è¡Œä¸€å€‹é—œéµè©ï¼š
é—œéµè©ä¸­æ–‡ / Keywords in English
"""
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä½æ·±è€•æ–¼ç”¢å“è¨­è¨ˆç ”ç©¶èˆ‡æ•™å­¸ç ”ç©¶çš„å°ˆæ¥­å­¸è¡“ç ”ç©¶è€…ï¼Œç†Ÿæ‚‰å„é ˜åŸŸçš„å­¸è¡“ç”¨èªï¼Œç‰¹åˆ¥æ˜¯åœ¨è¨­è¨ˆã€ç§‘æŠ€ã€äººæ–‡ç­‰è·¨é ˜åŸŸç ”ç©¶ä¸­å¸¸ç”¨çš„å°ˆæ¥­è¡“èªã€‚
åœ¨é¸æ“‡é—œéµè©æ™‚ï¼Œè«‹å„ªå…ˆä½¿ç”¨ï¼š
1. å°ç£å­¸è¡“ç•Œæ™®éæ¥å—çš„è¡“èªç¿»è­¯
2. å…·æœ‰å­¸è¡“æŒ‡æ¨™æ€§çš„å°ˆæ¥­ç”¨è©
3. ç¬¦åˆç ”ç©¶ä¸»é¡Œè„ˆçµ¡çš„ç”¨èª"""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        # è™•ç†å›æ‡‰
        keywords = response['choices'][0]['message']['content'].strip().splitlines()
        return [keyword.strip() for keyword in keywords if keyword.strip()]
    except Exception as e:
        st.error(f"ç”Ÿæˆé—œéµå­—æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return []

def generate_search_query(selected_keywords):
    """ç”Ÿæˆæœå°‹æŸ¥è©¢å­—ä¸²"""
    # å¾ä¸­è‹±å°ç…§æ ¼å¼ä¸­æå–è‹±æ–‡é—œéµå­—
    english_keywords = [k.split(' / ')[-1].strip() for k in selected_keywords]
    # åªç”¨ç©ºæ ¼é€£æ¥è‹±æ–‡é—œéµå­—
    return ' '.join(english_keywords)

def generate_titles(topic, content, literature_summary):
    """ä½¿ç”¨ OpenAI åªç”Ÿæˆç ”ç©¶é¡Œç›®é¸é …"""
    if not openai.api_key:
        st.error("OpenAI API é‡‘é‘°æœªè¨­ç½®ï¼")
        return None

    prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šï¼Œç”Ÿæˆä¸‰å€‹ç ”ç©¶é¡Œç›®é¸é …ï¼š

ç ”ç©¶ä¸»é¡Œï¼š
{topic}

ç ”ç©¶å…§å®¹ï¼š
{content}

æ–‡ç»è³‡æ–™ï¼š
{literature_summary}

è«‹ç”Ÿæˆä¸‰å€‹ä¸åŒæ–¹å‘çš„ç ”ç©¶é¡Œç›®ï¼š
1. ç†è«–å°å‘ï¼šåŸºæ–¼æ–‡ç»ä¸­çš„ç†è«–æ¡†æ¶ï¼Œæ¢è¨ç”¢å“è¨­è¨ˆèˆ‡æ•™å­¸ç ”ç©¶çš„ç†è«–åŸºç¤
2. å¯¦å‹™å°å‘ï¼šé‡å°æ–‡ç»ä¸­ç™¼ç¾çš„å¯¦å‹™å•é¡Œï¼Œæå‡ºå…·é«”çš„è¨­è¨ˆè§£æ±ºæ–¹æ¡ˆ
3. æ•´åˆå°å‘ï¼šçµåˆç†è«–èˆ‡å¯¦å‹™çš„å‰µæ–°è§’åº¦ï¼Œæ¢ç´¢è¨­è¨ˆæ•™è‚²çš„æ–°å¯èƒ½æ€§

è«‹ä¾ç…§ä»¥ä¸‹æ ¼å¼å›è¦†ï¼š

===å»ºè­°ç ”ç©¶é¡Œç›®===
1. ç†è«–å°å‘ï¼š
[ä¸­æ–‡é¡Œç›®] / [English Title]
ï¼ˆåŸºæ–¼ [ç›¸é—œæ–‡ç»ä½œè€…] çš„ç†è«–æ¡†æ¶ï¼‰

2. å¯¦å‹™å°å‘ï¼š
[ä¸­æ–‡é¡Œç›®] / [English Title]
ï¼ˆé‡å° [ç›¸é—œæ–‡ç»ä½œè€…] æå‡ºçš„å¯¦å‹™å•é¡Œï¼‰

3. æ•´åˆå°å‘ï¼š
[ä¸­æ–‡é¡Œç›®] / [English Title]
ï¼ˆçµåˆ [ç›¸é—œæ–‡ç»ä½œè€…] çš„ç†è«–èˆ‡å¯¦å‹™è§€é»ï¼‰
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä½æ·±è€•æ–¼ç”¢å“è¨­è¨ˆç ”ç©¶èˆ‡æ•™å­¸ç ”ç©¶çš„å°ˆæ¥­å­¸è¡“ç ”ç©¶è€…ï¼Œç¶“å¸¸çµåˆäººå·¥æ™ºæ…§ã€æ„Ÿæ¸¬è£ç½®ã€è™›æ“¬å¯¦å¢ƒèˆ‡äººæ©Ÿäº’å‹•ï¼Œè¦–å…¶ç‚ºã€Œæ„ŸçŸ¥æ¼”ç®—æ³•ã€ã€ã€Œå­˜åœ¨ç–‘å•ã€èˆ‡ã€Œå€«ç†ç•Œé¢ã€çš„æ¢ç´¢åª’ä»‹ã€‚"""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        st.error(f"ç”Ÿæˆç ”ç©¶é¡Œç›®æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def generate_full_content(research_topic, research_content, literature_summary, selected_title):
    """ç”Ÿæˆå®Œæ•´çš„ç ”ç©¶ç›®çš„å’Œåƒè€ƒæ–‡ç»"""
    try:
        # æ§‹å»ºæç¤ºè©
        prompt = f"""ä½ æ˜¯ä¸€ä½å…·æœ‰è±å¯Œç ”ç©¶èˆ‡å¯¦å‹™ç¶“é©—çš„å­¸è€…ï¼Œè«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šï¼Œä»¥è‡ªç„¶ä¸”å°ˆæ¥­çš„å­¸è¡“è«–è¿°æ–¹å¼ï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„ç ”ç©¶ç›®çš„å’Œåƒè€ƒæ–‡ç»ï¼š

ç ”ç©¶ä¸»é¡Œï¼š{research_topic}

ç ”ç©¶å…§å®¹ï¼š{research_content}

æ–‡ç»æ‘˜è¦ï¼š{literature_summary}

é¸å®šæ¨™é¡Œï¼š{selected_title}

ã€å¯«ä½œè¦æ±‚ã€‘
1. æ–‡ç« é¢¨æ ¼ï¼š
   - é‹ç”¨ç¬¬ä¸€äººç¨±æ•˜è¿°ï¼Œå±•ç¾ç ”ç©¶è€…çš„å°ˆæ¥­æ´å¯Ÿ
   - ä¿æŒå­¸è¡“åš´è¬¹æ€§çš„åŒæ™‚ï¼Œèå…¥å€‹äººè§€é»å’Œç¶“é©—
   - æ®µè½ä¹‹é–“è¦æœ‰è‡ªç„¶çš„é‚è¼¯æ¨å±•
   - é¿å…éæ–¼åˆ¶å¼åŒ–çš„è¡¨é”æ–¹å¼

2. è«–è¿°æ–¹å¼ï¼š
   - å¾å¯¦å‹™è§€å¯Ÿæˆ–ç†è«–ç¼ºå£åˆ‡å…¥å•é¡Œ
   - çµåˆå€‹äººç¶“é©—èˆ‡æ–‡ç»è­‰æ“š
   - å±•ç¾æ€è€ƒçš„æ·±åº¦èˆ‡å»£åº¦
   - é©åº¦èå…¥é ˜åŸŸå°ˆæ¥­è¡“èª

3. èªè¨€è¡¨é”ï¼š
   - ä½¿ç”¨æµæš¢ä¸”å°ˆæ¥­çš„å­¸è¡“ç”¨èª
   - é¿å…éåº¦å †ç Œæ–‡ç»
   - ä¿æŒè«–è¿°çš„é€£è²«æ€§å’Œé‚è¼¯æ€§
   - é©æ™‚ä½¿ç”¨è½‰æŠ˜èªå¥å¢åŠ æ–‡ç« æµæš¢åº¦

ã€å…§å®¹æ¶æ§‹ã€‘ï¼ˆè‡³å°‘1000å­—ï¼‰ï¼š

1. ç ”ç©¶èƒŒæ™¯èˆ‡å•é¡Œæ„è­˜ï¼ˆç´„400å­—ï¼‰ï¼š
   - å¾é ˜åŸŸç¾æ³æˆ–å¯¦å‹™è§€å¯Ÿåˆ‡å…¥
   - æŒ‡å‡ºå€¼å¾—ç ”ç©¶çš„å•é¡Œæˆ–ç¾è±¡
   - çµåˆç›¸é—œæ–‡ç»èªªæ˜ç ”ç©¶é‡è¦æ€§
   - å±•ç¾ç ”ç©¶å‹•æ©Ÿçš„ç™¼å±•è„ˆçµ¡

2. ç ”ç©¶ç›®æ¨™èˆ‡æ–¹æ³•ï¼ˆç´„400å­—ï¼‰ï¼š
   - æ¸…æ¥šèªªæ˜ç ”ç©¶ç›®çš„
   - è§£é‡‹ç ”ç©¶æ–¹æ³•çš„é¸æ“‡ç†ç”±
   - æè¿°ç ”ç©¶è¨­è¨ˆçš„æ€è€ƒé‚è¼¯
   - èªªæ˜é æœŸé”æˆçš„å…·é«”ç›®æ¨™

3. é æœŸè²¢ç»èˆ‡ç ”ç©¶åƒ¹å€¼ï¼ˆç´„200å­—ï¼‰ï¼š
   - èªªæ˜ç ”ç©¶çš„å­¸è¡“åƒ¹å€¼
   - æè¿°å¯¦å‹™æ‡‰ç”¨çš„å¯èƒ½æ€§
   - è¨è«–ç ”ç©¶çš„å‰µæ–°ä¹‹è™•
   - æå‡ºæœªä¾†ç ”ç©¶æ–¹å‘

è«‹æ³¨æ„ï¼š
1. æ–‡ç»å¼•ç”¨è¦è‡ªç„¶åœ°èå…¥è«–è¿°ä¸­ï¼ˆAPAæ ¼å¼ï¼‰
2. ç†è«–èˆ‡å¯¦å‹™çš„é€£çµè¦æœ‰èªªæœåŠ›
3. ç¢ºä¿ç ”ç©¶ç›®çš„çš„å¯è¡Œæ€§èˆ‡å‰µæ–°æ€§
4. æ•´é«”è«–è¿°è¦æµæš¢ä¸”å…·é‚è¼¯æ€§

æœ€å¾Œè«‹åˆ—å‡ºå®Œæ•´çš„åƒè€ƒæ–‡ç»ï¼ˆAPAæ ¼å¼ï¼‰ã€‚"""

        # ä½¿ç”¨ OpenAI API ç”Ÿæˆå…§å®¹
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œçš„å­¸è¡“ç ”ç©¶è€…ï¼Œæ“…é•·çµåˆç†è«–èˆ‡å¯¦å‹™ã€‚åœ¨æ’°å¯«æ™‚ï¼š
1. æ ¹æ“šç ”ç©¶ä¸»é¡Œèª¿æ•´å°ˆæ¥­è¡“èªå’Œè«–è¿°æ–¹å¼
2. è‡ªç„¶åœ°èå…¥ç ”ç©¶è€…çš„è§€å¯Ÿèˆ‡ç¶“é©—
3. å±•ç¾æ·±å…¥çš„æ€è€ƒéç¨‹å’Œé‚è¼¯æ¨æ¼”
4. ç¶­æŒå­¸è¡“åš´è¬¹æ€§å’Œå‰µæ–°æ€ç¶­
5. ç¢ºä¿æ–‡ç« çµæ§‹å®Œæ•´ä¸”è«–è¿°æµæš¢"""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2500
        )

        # æå–ç”Ÿæˆçš„å…§å®¹
        generated_text = response.choices[0].message.content.strip()
        
        # åˆ†å‰²ç ”ç©¶ç›®çš„å’Œåƒè€ƒæ–‡ç»
        parts = generated_text.split('åƒè€ƒæ–‡ç»')
        purpose_content = parts[0].strip()
        references_content = parts[1].strip() if len(parts) > 1 else ""

        return purpose_content, references_content

    except Exception as e:
        st.error(f"ç”Ÿæˆéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None, None

def save_research_purpose(content):
    """å°‡ç ”ç©¶ç›®çš„å…§å®¹å„²å­˜åˆ°æš«å­˜æª”æ¡ˆ"""
    with open('.research_purpose.tmp', 'w', encoding='utf-8') as f:
        json.dump({'research_purpose': content}, f, ensure_ascii=False)

def main():
    st.title("ç ”ç©¶ç›®çš„èˆ‡æ–‡ç»æ¢è¨ç”ŸæˆåŠ©æ‰‹")
    st.write("æ­¤å·¥å…·å°‡å”åŠ©æ‚¨ä»¥å°ˆæ¥­å­¸è¡“ç”¨èªæ’°å¯«ç ”ç©¶ç›®çš„é™³è¿°èˆ‡æ–‡ç»æ¢è¨ï¼Œæ•´åˆç†è«–æ¶æ§‹èˆ‡å¯¦å‹™æ‡‰ç”¨ã€‚")
    
    # æª¢æŸ¥ API é‡‘é‘°
    if not openai.api_key:
        st.error("è«‹è¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼")
        st.stop()
    
    # åˆå§‹åŒ– session state
    if 'step' not in st.session_state:
        st.session_state.step = 1
    if 'keywords' not in st.session_state:
        st.session_state.keywords = []
    if 'research_topic' not in st.session_state:
        st.session_state.research_topic = ""
    if 'research_content' not in st.session_state:
        st.session_state.research_content = ""
    if 'selected_keywords' not in st.session_state:
        st.session_state.selected_keywords = []
    if 'literature_summary' not in st.session_state:
        st.session_state.literature_summary = ""
    if 'generated_result' not in st.session_state:
        st.session_state.generated_result = None
    if 'selected_title' not in st.session_state:
        st.session_state.selected_title = None
    if 'generated_purpose' not in st.session_state:
        st.session_state.generated_purpose = None
    if 'references' not in st.session_state:
        st.session_state.references = None
    if 'collected_literature' not in st.session_state:
        st.session_state.collected_literature = {}
    
    # é¡¯ç¤ºç•¶å‰é€²åº¦
    if st.session_state.step > 1:
        with st.expander("å·²å®Œæˆçš„å…§å®¹", expanded=False):
            if st.session_state.research_topic:
                st.markdown("### ç ”ç©¶ä¸»é¡Œ")
                st.markdown(st.session_state.research_topic)
            if st.session_state.selected_title:
                st.markdown("### é¸å®šçš„ç ”ç©¶é¡Œç›®")
                st.markdown(st.session_state.selected_title['title'])
            if st.session_state.generated_purpose:
                st.markdown("### ç ”ç©¶ç›®çš„")
                st.markdown(st.session_state.generated_purpose)

    # ç¬¬ä¸€æ­¥ï¼šè¼¸å…¥ç ”ç©¶ä¸»é¡Œ
    st.header("ç¬¬ä¸€æ­¥ï¼šç ”ç©¶ä¸»é¡Œç•Œå®š")
    st.markdown("*è«‹é—¡è¿°æ‚¨çš„ç ”ç©¶ä¸»é¡Œï¼Œå¯åŒ…å«ç ”ç©¶å‹•æ©Ÿã€å•é¡Œæ„è­˜æˆ–ç†è«–æ¢è¨æ–¹å‘ã€‚*")
    research_topic = st.text_area("ç ”ç©¶ä¸»é¡Œï¼š", 
                                value=st.session_state.research_topic,
                                height=100,
                                key="topic_input",
                                help="å»ºè­°å¾ç†è«–ç¼ºå£æˆ–å¯¦å‹™å•é¡Œå‡ºç™¼ï¼Œèªªæ˜ç ”ç©¶åƒ¹å€¼")
    
    # ç¬¬äºŒæ­¥ï¼šè¼¸å…¥ç ”ç©¶æƒ³è¦æ¢è¨çš„å…§å®¹
    st.header("ç¬¬äºŒæ­¥ï¼šç ”ç©¶å…§å®¹è¦åŠƒ")
    st.markdown("*è«‹è©³è¿°æ‚¨çš„ç ”ç©¶è¦åŠƒï¼ŒåŒ…å«ç ”ç©¶æ–¹æ³•ã€ç†è«–æ¶æ§‹ã€ç ”ç©¶å°è±¡ç­‰è¦ç´ ã€‚*")
    research_content = st.text_area("ç ”ç©¶å…§å®¹ï¼š",
                                  value=st.session_state.research_content,
                                  height=150,
                                  key="content_input",
                                  help="å¯åŒ…å«ï¼šç†è«–åŸºç¤ã€ç ”ç©¶æ–¹æ³•ã€ç ”ç©¶å°è±¡ã€é æœŸè²¢ç»")
    
    # ç”Ÿæˆé—œéµå­—æŒ‰éˆ•
    if st.button("ç”¢ç”Ÿé—œéµè©", key="generate_keywords_button"):
        if research_topic and research_content:
            st.session_state.research_topic = research_topic
            st.session_state.research_content = research_content
            with st.spinner("æ­£åœ¨ç”¢ç”Ÿé—œéµè©..."):
                keywords = generate_keywords(research_topic, research_content)
                if keywords:
                    st.session_state.keywords = keywords
                    st.session_state.step = 2
        else:
            st.error("è«‹å®Œæ•´å¡«å¯«ç ”ç©¶ä¸»é¡Œèˆ‡ç ”ç©¶å…§å®¹ï¼")
    
    # é¡¯ç¤ºé—œéµå­—é¸æ“‡ï¼ˆå¦‚æœå·²ç”Ÿæˆï¼‰
    if st.session_state.step >= 2 and st.session_state.keywords:
        st.header("ç¬¬ä¸‰æ­¥ï¼šé—œéµè©é¸æ“‡")
        st.markdown("*è«‹é¸æ“‡æœ€èƒ½ä»£è¡¨æ‚¨ç ”ç©¶æ ¸å¿ƒæ¦‚å¿µçš„é—œéµè©ã€‚*")
        selected_keywords = st.multiselect(
            "é—œéµè©é¸æ“‡ï¼š",
            st.session_state.keywords,
            default=st.session_state.keywords[:5],
            key="keyword_selector",
            help="å»ºè­°é¸æ“‡ 5-7 å€‹æœ€å…·ä»£è¡¨æ€§çš„é—œéµè©"
        )
        
        if selected_keywords:
            st.session_state.selected_keywords = selected_keywords
            search_query = generate_search_query(selected_keywords)
            
            st.header("ç¬¬å››æ­¥ï¼šæ–‡ç»æª¢ç´¢")
            st.markdown("*ä½¿ç”¨ç³»çµ±ç”Ÿæˆçš„æª¢ç´¢å­—ä¸²åœ¨ SciSpace é€²è¡Œæ–‡ç»æœå°‹ã€‚*")
            st.write("æª¢ç´¢å­—ä¸²ï¼š")
            st.code(search_query)
            
            # æä¾› SciSpace é€£çµ
            scispace_url = f"https://scispace.com/search?q={search_query}"
            st.markdown(f"[å‰å¾€ SciSpace æœå°‹ç›¸é—œæ–‡ç»]({scispace_url})")
            
            # ç¬¬äº”æ­¥ï¼šæ–‡ç»æ‘˜è¦è¼¸å…¥
            st.header("ç¬¬äº”æ­¥ï¼šæ–‡ç»å›é¡§å½™æ•´")
            st.markdown("*è«‹ä¾åºè¼¸å…¥æ–‡ç»çš„ APA æ ¼å¼å¼•ç”¨è³‡è¨Šï¼Œä»¥åŠæ–‡ç»çš„é‡è¦å…§å®¹æ‘˜è¦ã€‚*")
            literature_summary = st.text_area(
                "æ–‡ç»è³‡æ–™ï¼š",
                height=300,
                key="literature_input",
                help="""è«‹ä¾ç…§ä»¥ä¸‹æ ¼å¼è¼¸å…¥ï¼š

1. APA æ ¼å¼å¼•ç”¨ï¼š
[è«‹è²¼ä¸Šå®Œæ•´çš„ APA æ ¼å¼æ–‡ç»è³‡è¨Š]

2. æ–‡ç»é‡è¦å…§å®¹ï¼š
- ç ”ç©¶ç›®çš„
- é‡è¦ç™¼ç¾
- ç ”ç©¶æ–¹æ³•
- ç†è«–æ¶æ§‹
- ç ”ç©¶è²¢ç»
                """
            )
            
            # ç”Ÿæˆç ”ç©¶é¡Œç›®æŒ‰éˆ•
            if st.button("ç”Ÿæˆç ”ç©¶é¡Œç›®", key="generate_titles_button"):
                if literature_summary:
                    st.session_state.literature_summary = literature_summary
                    with st.spinner("æ­£åœ¨ç”Ÿæˆç ”ç©¶é¡Œç›®é¸é …..."):
                        titles_result = generate_titles(
                            st.session_state.research_topic,
                            st.session_state.research_content,
                            literature_summary
                        )
                        if titles_result:
                            st.session_state.generated_titles = titles_result
                            st.session_state.step = 6
                            st.rerun()

    # é¡¯ç¤ºé¡Œç›®é¸æ“‡
    if st.session_state.step == 6 and st.session_state.get('generated_titles'):
        st.header("ç¬¬å…­æ­¥ï¼šé¸æ“‡ç ”ç©¶é¡Œç›®")
        titles_section = st.session_state.generated_titles.split('===å»ºè­°ç ”ç©¶é¡Œç›®===')
        if len(titles_section) > 1:
            titles_content = titles_section[1].strip()
            titles = []
            current_title = {"type": "", "title": "", "description": ""}
            
            for line in titles_content.splitlines():
                line = line.strip()
                if not line:
                    continue
                if line.startswith('1. ') or line.startswith('2. ') or line.startswith('3. '):
                    if current_title["title"]:
                        titles.append(current_title.copy())
                        current_title = {"type": "", "title": "", "description": ""}
                    current_title["type"] = line
                elif '/' in line and not line.startswith('ï¼ˆ'):
                    current_title["title"] = line
                elif line.startswith('ï¼ˆ'):
                    current_title["description"] = line
            
            if current_title["title"]:
                titles.append(current_title.copy())
            
            st.markdown("### è«‹é¸æ“‡ç ”ç©¶é¡Œç›®")
            for i, title in enumerate(titles):
                with st.container():
                    st.markdown(f"**{title['type']}**")
                    st.markdown(f"**é¡Œç›®ï¼š** {title['title']}")
                    st.markdown(f"**èªªæ˜ï¼š** {title['description']}")
                    if st.button(f"é¸æ“‡æ­¤é¡Œç›®", key=f"select_title_{i}"):
                        st.session_state.selected_title = title
                        st.session_state.step = 7
                        st.rerun()
                st.markdown("---")

    # ç”Ÿæˆå®Œæ•´å…§å®¹
    if st.session_state.step == 7 and st.session_state.get('selected_title'):
        st.header("ç¬¬ä¸ƒæ­¥ï¼šç”Ÿæˆç ”ç©¶ç›®çš„")
        st.info(f"**å·²é¸æ“‡çš„é¡Œç›®ï¼š**\n\n{st.session_state.selected_title['title']}\n\n**é¡å‹ï¼š**\n{st.session_state.selected_title['type']}\n\n**èªªæ˜ï¼š**\n{st.session_state.selected_title['description']}")
        
        # æª¢æŸ¥è¼¸å…¥è³‡æ–™å®Œæ•´æ€§
        if not st.session_state.literature_summary or len(st.session_state.literature_summary.strip()) < 100:
            st.warning("âš ï¸ è«‹ç¢ºä¿æä¾›è¶³å¤ è©³ç´°çš„æ–‡ç»è³‡æ–™ï¼Œé€™å°‡æœ‰åŠ©æ–¼ç”Ÿæˆæ›´å¥½çš„ç ”ç©¶ç›®çš„ã€‚")
            st.markdown("""
            **æ–‡ç»è³‡æ–™æ‡‰åŒ…å«ï¼š**
            1. å®Œæ•´çš„ APA æ ¼å¼å¼•ç”¨
            2. æ–‡ç»çš„ä¸»è¦ç™¼ç¾
            3. ç ”ç©¶æ–¹æ³•èªªæ˜
            4. ç†è«–æ¡†æ¶æè¿°
            5. ç ”ç©¶è²¢ç»èªªæ˜
            """)
        
        # ç”Ÿæˆç ”ç©¶ç›®çš„æŒ‰éˆ•
        if st.button("ç”Ÿæˆå®Œæ•´ç ”ç©¶ç›®çš„"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆç ”ç©¶ç›®çš„..."):
                # ç›´æ¥èª¿ç”¨ç”Ÿæˆå‡½æ•¸
                purpose_content, references = generate_full_content(
                    st.session_state.research_topic,
                    st.session_state.research_content,
                    st.session_state.literature_summary,
                    st.session_state.selected_title
                )
                
                if purpose_content and references:
                    st.session_state.generated_purpose = purpose_content
                    st.session_state.references = references
                    
                    # é¡¯ç¤ºç”Ÿæˆçš„å…§å®¹
                    st.markdown("## ğŸ“ ç ”ç©¶ç›®çš„")
                    st.info(f"**{st.session_state.selected_title}**")
                    st.markdown(st.session_state.generated_purpose)
                    st.caption(f"*å…§å®¹é•·åº¦ï¼š{len(st.session_state.generated_purpose)} å­—*")
                    
                    st.markdown("### ğŸ“š åƒè€ƒæ–‡ç»")
                    st.markdown(st.session_state.references)
                    st.caption(f"*åƒè€ƒæ–‡ç»æ•¸é‡ï¼š{len(st.session_state.references.splitlines())} ç­†*")
                    
                    # å„²å­˜ç ”ç©¶ç›®çš„å…§å®¹
                    save_research_purpose(st.session_state.generated_purpose)
                else:
                    st.error("ç”Ÿæˆå…§å®¹å¤±æ•—ï¼Œè«‹é‡è©¦ã€‚")

    # å¦‚æœå·²ç¶“ç”Ÿæˆå…§å®¹ï¼Œé¡¯ç¤ºã€Œé–‹å§‹æ–‡ç»åˆ†æã€æŒ‰éˆ•
    if st.session_state.generated_purpose:
        if st.button("é–‹å§‹æ–‡ç»åˆ†æ"):
            # å•Ÿå‹•æ–‡ç»åˆ†æå·¥å…·
            try:
                subprocess.Popen(["streamlit", "run", "literature_analysis.py"])
                st.success("å·²é–‹å•Ÿæ–‡ç»åˆ†æå·¥å…·ï¼Œè«‹åˆ‡æ›åˆ°æ–°é–‹å•Ÿçš„è¦–çª—ç¹¼çºŒæ“ä½œã€‚")
            except Exception as e:
                st.error(f"å•Ÿå‹•æ–‡ç»åˆ†æå·¥å…·æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")

    # æ–‡ç»æ¢è¨éšæ®µ
    if st.session_state.step == 8:
        st.header("æ–‡ç»æ¢è¨éšæ®µ")
        
        # é¡¯ç¤ºå·²é¸æ“‡çš„é¡Œç›®å’Œç ”ç©¶ç›®çš„
        st.markdown("### å·²é¸æ“‡çš„ç ”ç©¶é¡Œç›®")
        st.markdown(st.session_state.selected_title)
        st.markdown("### ç ”ç©¶ç›®çš„")
        st.markdown(st.session_state.generated_purpose)
        st.markdown("### ç›®å‰çš„åƒè€ƒæ–‡ç»")
        st.markdown(st.session_state.references)
        
        # ç”Ÿæˆæ–‡ç»æ¢è¨æ¶æ§‹
        if not st.session_state.get('literature_sections'):
            with st.spinner("æ­£åœ¨åˆ†æç ”ç©¶ç›®çš„ï¼Œè¦åŠƒæ–‡ç»æ¢è¨æ¶æ§‹..."):
                sections = generate_literature_review_sections(
                    st.session_state.selected_title,
                    st.session_state.generated_purpose,
                    st.session_state.references
                )
                st.session_state.literature_sections = sections
        
        # é¡¯ç¤ºæ–‡ç»æ¢è¨æ¶æ§‹å’Œæœå°‹å»ºè­°
        if st.session_state.literature_sections:
            st.subheader("æ–‡ç»æ¢è¨æ¶æ§‹")
            for section in st.session_state.literature_sections:
                with st.expander(f"ç¬¬ {section['order']} ç¯€ï¼š{section['title']}", expanded=True):
                    st.markdown(f"**èªªæ˜ï¼š** {section['description']}")
                    st.markdown("**å»ºè­°æœå°‹é—œéµå­—ï¼š**")
                    st.code(section['search_terms'])
                    
                    # æ–‡ç»æ”¶é›†å€
                    st.markdown("### æ–‡ç»æ”¶é›†")
                    literature_key = f"literature_{section['order']}"
                    if literature_key not in st.session_state.collected_literature:
                        st.session_state.collected_literature[literature_key] = []
                    
                    # æ–°å¢æ–‡ç»è¡¨å–®
                    with st.form(f"add_literature_{section['order']}"):
                        apa_citation = st.text_area("APA å¼•ç”¨æ ¼å¼ï¼š", key=f"apa_{section['order']}")
                        summary = st.text_area("æ–‡ç»æ‘˜è¦ï¼š", key=f"summary_{section['order']}")
                        if st.form_submit_button("æ–°å¢æ–‡ç»"):
                            if apa_citation and summary:
                                st.session_state.collected_literature[literature_key].append({
                                    'citation': apa_citation,
                                    'summary': summary
                                })
                                st.success("æ–‡ç»å·²æ–°å¢ï¼")
                                st.rerun()
                    
                    # é¡¯ç¤ºå·²æ”¶é›†çš„æ–‡ç»
                    if st.session_state.collected_literature[literature_key]:
                        st.markdown("**å·²æ”¶é›†çš„æ–‡ç»ï¼š**")
                        for i, lit in enumerate(st.session_state.collected_literature[literature_key]):
                            st.markdown(f"æ–‡ç» {i+1}:")
                            st.markdown(f"å¼•ç”¨: {lit['citation']}")
                            st.markdown(f"æ‘˜è¦: {lit['summary']}")
                            st.markdown("---")
            
            # ç”Ÿæˆæ–‡ç»æ¢è¨æŒ‰éˆ•
            if st.button("ç”Ÿæˆæ–‡ç»æ¢è¨", key="generate_literature_review"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ–‡ç»æ¢è¨..."):
                    literature_review = generate_full_literature_review(
                        st.session_state.selected_title,
                        st.session_state.generated_purpose,
                        st.session_state.literature_sections,
                        st.session_state.collected_literature
                    )
                    if literature_review:
                        st.markdown("### æ–‡ç»æ¢è¨")
                        st.markdown(literature_review['content'])
                        st.markdown("### æ›´æ–°å¾Œçš„åƒè€ƒæ–‡ç»")
                        st.markdown(literature_review['references'])
                        st.session_state.references = literature_review['references']
                        st.success("æ–‡ç»æ¢è¨å·²ç”Ÿæˆå®Œæˆï¼")

def generate_literature_review_sections(title, purpose, references):
    """ç”Ÿæˆæ–‡ç»æ¢è¨çš„åˆ†ç¯€æ¶æ§‹"""
    prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹ç ”ç©¶è³‡è¨Šï¼Œè¦åŠƒæ–‡ç»æ¢è¨çš„æ¶æ§‹ï¼š

ç ”ç©¶é¡Œç›®ï¼š
{title}

ç ”ç©¶ç›®çš„ï¼š
{purpose}

ç›®å‰çš„åƒè€ƒæ–‡ç»ï¼š
{references}

è«‹è¦åŠƒ 3-5 å€‹æ–‡ç»æ¢è¨çš„ä¸»è¦æ®µè½ï¼Œæ¯å€‹æ®µè½éœ€åŒ…å«ï¼š
1. æ®µè½æ¨™é¡Œ
2. å…§å®¹èªªæ˜
3. å»ºè­°çš„æœå°‹é—œéµå­—ï¼ˆä¸­è‹±å°ç…§ï¼‰

å›è¦†æ ¼å¼ï¼š
===æ®µè½1===
æ¨™é¡Œï¼š[æ®µè½æ¨™é¡Œ]
èªªæ˜ï¼š[æœ¬æ®µè½è¦æ¢è¨çš„é‡é»]
æœå°‹é—œéµå­—ï¼š[é—œéµå­—åˆ—è¡¨]

===æ®µè½2===
...ä»¥æ­¤é¡æ¨
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å­¸è¡“ç ”ç©¶è€…ï¼Œæ“…é•·è¦åŠƒæ–‡ç»æ¢è¨æ¶æ§‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        result = response.choices[0].message.content.strip()
        sections = []
        current_section = {}
        
        for line in result.splitlines():
            if line.startswith('===æ®µè½') and line.endswith('==='):
                if current_section:
                    sections.append(current_section)
                current_section = {'order': len(sections) + 1}
            elif line.startswith('æ¨™é¡Œï¼š'):
                current_section['title'] = line.replace('æ¨™é¡Œï¼š', '').strip()
            elif line.startswith('èªªæ˜ï¼š'):
                current_section['description'] = line.replace('èªªæ˜ï¼š', '').strip()
            elif line.startswith('æœå°‹é—œéµå­—ï¼š'):
                current_section['search_terms'] = line.replace('æœå°‹é—œéµå­—ï¼š', '').strip()
        
        if current_section:
            sections.append(current_section)
        
        return sections
    except Exception as e:
        st.error(f"ç”Ÿæˆæ–‡ç»æ¢è¨æ¶æ§‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

def generate_full_literature_review(title, purpose, sections, collected_literature):
    """ç”Ÿæˆå®Œæ•´çš„æ–‡ç»æ¢è¨å…§å®¹"""
    prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™ï¼Œæ’°å¯«ä¸€ä»½å®Œæ•´çš„æ–‡ç»æ¢è¨ï¼ˆè‡³å°‘ 3500 å­—ï¼‰ï¼š

ç ”ç©¶é¡Œç›®ï¼š
{title}

ç ”ç©¶ç›®çš„ï¼š
{purpose}

å„ç¯€æ–‡ç»è³‡æ–™ï¼š
{json.dumps(collected_literature, ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. ç¸½å­—æ•¸è‡³å°‘ 3500 å­—
2. ä¾ç…§å„ç¯€è¦åŠƒçš„ä¸»é¡Œåˆ†æ®µæ’°å¯«
3. æ¯æ®µæ–‡ç»éƒ½è¦é©ç•¶å¼•ç”¨ä¸¦æ•´åˆç›¸é—œæ–‡ç»
4. æ®µè½ä¹‹é–“è¦æœ‰é©ç•¶çš„è½‰æŠ˜
5. æœ€å¾Œè¦åˆ—å‡ºå®Œæ•´çš„åƒè€ƒæ–‡ç»ï¼ˆAPAæ ¼å¼ï¼‰

è«‹ä¾ç…§ä»¥ä¸‹æ ¼å¼å›è¦†ï¼š

===æ–‡ç»æ¢è¨===
[3500å­—ä»¥ä¸Šçš„æ–‡ç»æ¢è¨å…§å®¹]

===åƒè€ƒæ–‡ç»===
[APAæ ¼å¼çš„åƒè€ƒæ–‡ç»åˆ—è¡¨]
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å­¸è¡“ç ”ç©¶è€…ï¼Œæ“…é•·æ’°å¯«æ–‡ç»æ¢è¨ã€‚
ç‰¹é»ï¼š
- å–„æ–¼æ•´åˆä¸åŒæ–‡ç»çš„è§€é»
- èƒ½æº–ç¢ºä½¿ç”¨ APA å¼•ç”¨æ ¼å¼
- æ“…é•·å»ºç«‹æ–‡ç»ä¹‹é–“çš„å°è©±
- èƒ½æœ‰æ•ˆçµ„ç¹”é•·ç¯‡å¹…çš„å­¸è¡“è«–è¿°"""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        result = response.choices[0].message.content.strip()
        parts = result.split('===åƒè€ƒæ–‡ç»===')
        
        return {
            'content': parts[0].replace('===æ–‡ç»æ¢è¨===', '').strip(),
            'references': parts[1].strip() if len(parts) > 1 else ''
        }
    except Exception as e:
        st.error(f"ç”Ÿæˆæ–‡ç»æ¢è¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return None

if __name__ == "__main__":
    main() 